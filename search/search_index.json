{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Clinical Epidemiology Wiki The Clinical Epidemiology Wiki is a personal project of mine in creating a repository of statistical and epidemiological concepts. As you can see this site is split up into a few sections: Biostatistics (and data science) Clinical Epidemiology Healthcare Economics Evidence Based Medicine I hope to build this site out more as I delve deeper into clinical epidemiology, biostatistics and data science. My personal goal for this website is to be a repository of all new knowledge I come across (and things of interest) in this world of research. Of particular interest is the use of advanced statistical methods - my goal is to emphasize mathematical and statistical rigour in developing this site, and hopefully provide a guided pathway for your own understanding of biostatistics. Moreover, as new methods in data science trickles into medical research (e.g. machine learning), I hope to provide a medical statistics-centric perspective on this area of research. I aim to continue adding to this website as the field of clinical epidemiology and biostatistics develops.","title":"Clinical Epidemiology Wiki"},{"location":"#clinical-epidemiology-wiki","text":"The Clinical Epidemiology Wiki is a personal project of mine in creating a repository of statistical and epidemiological concepts. As you can see this site is split up into a few sections: Biostatistics (and data science) Clinical Epidemiology Healthcare Economics Evidence Based Medicine I hope to build this site out more as I delve deeper into clinical epidemiology, biostatistics and data science. My personal goal for this website is to be a repository of all new knowledge I come across (and things of interest) in this world of research. Of particular interest is the use of advanced statistical methods - my goal is to emphasize mathematical and statistical rigour in developing this site, and hopefully provide a guided pathway for your own understanding of biostatistics. Moreover, as new methods in data science trickles into medical research (e.g. machine learning), I hope to provide a medical statistics-centric perspective on this area of research. I aim to continue adding to this website as the field of clinical epidemiology and biostatistics develops.","title":"Clinical Epidemiology Wiki"},{"location":"about/","text":"About the ClinEpi Wiki About this project This website and project was designed for a few reasons: To improve access to education in Evidence Based Medicine and Clinical Epidemiology To provide an easily navigatable directory for biostatistics information As a way for me to personally organise my thoughts around clinical epidemiology and biostatistics, and record things that I have learnt To act as a portfolio in Clin Epi teaching As a place to organise information for the EBM-based podcast About the author Weber Liu BSc(Adv) MD MSci(Clin Epid) Further reading The following resources were used to develop the content for this website: University of Sydney: Masters of Science in Medicine (Clinical Epidemiology) degree Kenneth Rothman: Modern Epidemiology Martin Bland: Introduction to Medical Statistics Disclaimer By using this site you are agreeing to the following disclaimer - it was stolen from LITFL because it is a relevant FOAM-like blog, similar to what I am building here: This blog pro\u00advides gen\u00aderal infor\u00adma\u00adtion and dis\u00adcus\u00adsion about med\u00adi\u00adcine, health and related sub\u00adjects. The words and other con\u00adtent pro\u00advided in this blog, and in any linked mate\u00adri\u00adals, are not intended and should not be con\u00adstrued as med\u00adical advice. If the reader or any other per\u00adson has a med\u00adical con\u00adcern, he or she should con\u00adsult with an appropriately-licensed physi\u00adcian or other health care worker. Never dis\u00adre\u00adgard pro\u00adfes\u00adsional med\u00adical advice or delay in seek\u00ading it because of some\u00adthing you have read on this blog or in any linked materials. If you think you may have a med\u00adical emer\u00adgency, call your doc\u00adtor or 000 immediately. The views expressed on this blog and web\u00adsite have no rela\u00adtion to those of any academic, hospital, practice or other insti\u00adtu\u00adtion with which the authors are affiliated. TERMS OF USE AGREEMENT: This Terms of Use Agree\u00adment (\u201cagree\u00adment\u201d) is entered between and by \u201cyou\u201d (the reader or any other user of this weblog, also known as EpiWiki, the \u201cSite\u201d), Dr Weber Liu (the \u201cPrincipal author\u201d) and the EpiWiki team (the \u2018team\u2019). Access to the Site, and any use thereof, is sub\u00adject to the terms and con\u00addi\u00adtions set forth herein. By access\u00ading, read\u00ading or oth\u00ader\u00adwise using the Site, you hereby agree to these terms and conditions. This agree\u00adment con\u00adtains dis\u00adclaimers and other pro\u00advi\u00adsions that limit the Author\u2019s lia\u00adbil\u00adity to you. Please read these terms and con\u00addi\u00adtions fully and care\u00adfully. If you do not agree to be bound to each and every term and con\u00addi\u00adtion set forth herein, please exit the Site and do not access, read or oth\u00ader\u00adwise use infor\u00adma\u00adtion pro\u00advided herein. By access\u00ading the Site and/or read\u00ading its con\u00adtent, and/or using it to find infor\u00adma\u00adtion on any other web\u00adsite or infor\u00adma\u00adtional resource, you acknowl\u00adedge and agree that you have read and under\u00adstand these terms and con\u00addi\u00adtions, that the pro\u00advi\u00adsions, dis\u00adclo\u00adsures and dis\u00adclaimers set forth herein are fair and rea\u00adson\u00adable, and that your agree\u00adment to fol\u00adlow and be bound by these terms and con\u00addi\u00adtions is vol\u00adun\u00adtary and is not the result of fraud, duress or undue influ\u00adence exer\u00adcised upon you by any per\u00adson or entity. DISCLAIMER REGARDING MEDICAL ADVICE The Principal author pro\u00advides the Site and anyser\u00advices, infor\u00adma\u00adtion, opinions, con\u00adtent, ref\u00ader\u00adences and links to other knowl\u00adedge resources (col\u00adlec\u00adtively, \u201cCon\u00adtent\u201d) for infor\u00adma\u00adtional pur\u00adposes only. The Author does not pro\u00advide any med\u00adical advice on the Site. Access\u00ading, read\u00ading or oth\u00ader\u00adwise using the Site does not cre\u00adate a physician-patient rela\u00adtion\u00adship between you and the Principal author. Pro\u00advid\u00ading per\u00adsonal or med\u00adical infor\u00adma\u00adtion to the Principal author does not cre\u00adate a physician-patient rela\u00adtion\u00adship between you and the Principal author or authors. Noth\u00ading con\u00adtained in the Site is intended to estab\u00adlish a physician-patient rela\u00adtion\u00adship, to replace the ser\u00advices of a trained physi\u00adcian or health care pro\u00adfes\u00adsional, or oth\u00ader\u00adwise to be a sub\u00adsti\u00adtute for pro\u00adfes\u00adsional med\u00adical advice, diag\u00adno\u00adsis, or treatment. You hereby agree that you shall not make any med\u00adical or health-related deci\u00adsion based in whole or in part on any\u00adthing con\u00adtained in the Site. You should not rely on any infor\u00adma\u00adtion con\u00adtained in the Site and related mate\u00adri\u00adals in mak\u00ading med\u00adical, health-related or other deci\u00adsions. You should con\u00adsult a licensed physi\u00adcian or appropriately-credentialed health care worker in your com\u00admu\u00adnity in all mat\u00adters relat\u00ading to your health. DISCLAIMER REGARDING SITE CONTENT AND RELATED MATERIALS The Con\u00adtent may be changed with\u00adout notice and is not guar\u00adan\u00adteed to be com\u00adplete, cor\u00adrect, timely, cur\u00adrent or up-to-date. Sim\u00adi\u00adlar to any printed mate\u00adri\u00adals, the Con\u00adtent may become out-of-date. The Author under\u00adtakes no oblig\u00ada\u00adtion to update any Con\u00adtent on the Site. The Principal author may update the Con\u00adtent at any time with\u00adout notice, based on the Principal author\u2019s sole and absolute dis\u00adcre\u00adtion. The Principal author reserves the right to make alter\u00adations or dele\u00adtions to the Con\u00adtent at any time with\u00adout notice. Opin\u00adions expressed in the Site are not nec\u00ades\u00adsar\u00adily those of the Principal author or team. Any opin\u00adions of the Principal author have been con\u00adsid\u00adered in the con\u00adtext of cer\u00adtain con\u00addi\u00adtions and sub\u00adject to assump\u00adtions that can\u00adnot nec\u00ades\u00adsar\u00adily be applied to an indi\u00advid\u00adual case or par\u00adtic\u00adu\u00adlar cir\u00adcum\u00adstance. The Con\u00adtent may not and should not be used or relied upon for any other pur\u00adpose, includ\u00ading, but not lim\u00adited to, use in or in con\u00adnec\u00adtion with any legal proceeding. From time to time, the Site may con\u00adtain health\u2013 or medical-related infor\u00adma\u00adtion that is sex\u00adu\u00adally explicit. If you find this infor\u00adma\u00adtion offen\u00adsive, you may not want to use the Site. DISCLAIMER REGARDING THIRD PARTY LINKS The Site may, from time to time, con\u00adtain links to other (\u201cthird party\u201d) web sites. These links are pro\u00advided solely as a con\u00adve\u00adnience and not as a guar\u00adan\u00adtee or rec\u00adom\u00admen\u00adda\u00adtion by the Principal author for the ser\u00advices, infor\u00adma\u00adtion, opin\u00adion or any other con\u00adtent on such third party web sites or as an indi\u00adca\u00adtion of any affil\u00adi\u00ada\u00adtion, spon\u00adsor\u00adship or endorse\u00adment of such third party web sites. If you decide to access a linked web\u00adsite, you do so at your own risk. Your use of other web\u00adsites is sub\u00adject to the terms of use for such sites. The Principal author is not respon\u00adsi\u00adble for the con\u00adtent of any linked or oth\u00ader\u00adwise con\u00adnected web sites. The Principal author does not make any rep\u00adre\u00adsen\u00adta\u00adtions or guar\u00adan\u00adtees regard\u00ading the pri\u00advacy prac\u00adtices of, or the con\u00adtent or accu\u00adracy of mate\u00adri\u00adals included in, any linked or third party web\u00adsites. The inclu\u00adsion of third party adver\u00adtise\u00adments on the Site does not con\u00adsti\u00adtute an endorse\u00adment, guar\u00adan\u00adtee, or rec\u00adom\u00admen\u00adda\u00adtion. The Principal author makes no rep\u00adre\u00adsen\u00adta\u00adtions and/or guar\u00adan\u00adtees regard\u00ading any prod\u00aduct or ser\u00advice con\u00adtained therein. DISCLAIMER OF ALL WARRANTIES Con\u00adtent made avail\u00adable at the Site is pro\u00advided on an \u201cas is\u201d and \u201cas avail\u00adable\u201d basis with\u00adout war\u00adranties of any kind, either express or implied. Under no cir\u00adcum\u00adstances, as a result of your use of the Site, will the Principal author be liable to you or to any other per\u00adson for any direct, indi\u00adrect, inci\u00adden\u00adtal, con\u00adse\u00adquen\u00adtial, spe\u00adcial, exem\u00adplary or other dam\u00adages under any legal the\u00adory, includ\u00ading, with\u00adout lim\u00adi\u00adta\u00adtion, tort, con\u00adtract, strict lia\u00adbil\u00adity or oth\u00ader\u00adwise, even if advised of the pos\u00adsi\u00adbil\u00adity of such damages. AGE RESTRICTION The Site is intended for per\u00adsons eigh\u00adteen (18) years or older. Per\u00adsons under the age of eigh\u00adteen (18) should not access, use and/or browse the Site. INDEMNIFICATION You agree to indem\u00adnify and hold the Author harm\u00adless from any claim or demand, includ\u00ading attor\u00adneys\u2019 fees, made by any third party as a result of (1) any con\u00adtent posted or made avail\u00adable by you on this Site, (2) any vio\u00adla\u00adtion of law that occurs by you through the Site, and/or (3) any\u00adthing you do using the Site and/or the Con\u00adtent con\u00adtained therein. MODIFICATION The Author may mod\u00adify the terms and con\u00addi\u00adtions of this Agree\u00adment in whole or in party at any time for any rea\u00adson with\u00adout any notice to you, based on her dis\u00adcre\u00adtion. Such mod\u00adi\u00adfied terms and con\u00addi\u00adtions shall super\u00adsede these terms and con\u00addi\u00adtions and shall become bind\u00ading when pub\u00adlished online on the Site. ENTIRE AGREEMENT You accept that this Agree\u00adment rep\u00adre\u00adsents the entire under\u00adstand\u00ading between you and the Author con\u00adcern\u00ading use of the Site.","title":"About"},{"location":"about/#about-the-clinepi-wiki","text":"","title":"About the ClinEpi Wiki"},{"location":"about/#about-this-project","text":"This website and project was designed for a few reasons: To improve access to education in Evidence Based Medicine and Clinical Epidemiology To provide an easily navigatable directory for biostatistics information As a way for me to personally organise my thoughts around clinical epidemiology and biostatistics, and record things that I have learnt To act as a portfolio in Clin Epi teaching As a place to organise information for the EBM-based podcast","title":"About this project"},{"location":"about/#about-the-author","text":"Weber Liu BSc(Adv) MD MSci(Clin Epid)","title":"About the author"},{"location":"about/#further-reading","text":"The following resources were used to develop the content for this website: University of Sydney: Masters of Science in Medicine (Clinical Epidemiology) degree Kenneth Rothman: Modern Epidemiology Martin Bland: Introduction to Medical Statistics","title":"Further reading"},{"location":"about/#disclaimer","text":"By using this site you are agreeing to the following disclaimer - it was stolen from LITFL because it is a relevant FOAM-like blog, similar to what I am building here: This blog pro\u00advides gen\u00aderal infor\u00adma\u00adtion and dis\u00adcus\u00adsion about med\u00adi\u00adcine, health and related sub\u00adjects. The words and other con\u00adtent pro\u00advided in this blog, and in any linked mate\u00adri\u00adals, are not intended and should not be con\u00adstrued as med\u00adical advice. If the reader or any other per\u00adson has a med\u00adical con\u00adcern, he or she should con\u00adsult with an appropriately-licensed physi\u00adcian or other health care worker. Never dis\u00adre\u00adgard pro\u00adfes\u00adsional med\u00adical advice or delay in seek\u00ading it because of some\u00adthing you have read on this blog or in any linked materials. If you think you may have a med\u00adical emer\u00adgency, call your doc\u00adtor or 000 immediately. The views expressed on this blog and web\u00adsite have no rela\u00adtion to those of any academic, hospital, practice or other insti\u00adtu\u00adtion with which the authors are affiliated.","title":"Disclaimer"},{"location":"about/#terms-of-use-agreement","text":"This Terms of Use Agree\u00adment (\u201cagree\u00adment\u201d) is entered between and by \u201cyou\u201d (the reader or any other user of this weblog, also known as EpiWiki, the \u201cSite\u201d), Dr Weber Liu (the \u201cPrincipal author\u201d) and the EpiWiki team (the \u2018team\u2019). Access to the Site, and any use thereof, is sub\u00adject to the terms and con\u00addi\u00adtions set forth herein. By access\u00ading, read\u00ading or oth\u00ader\u00adwise using the Site, you hereby agree to these terms and conditions. This agree\u00adment con\u00adtains dis\u00adclaimers and other pro\u00advi\u00adsions that limit the Author\u2019s lia\u00adbil\u00adity to you. Please read these terms and con\u00addi\u00adtions fully and care\u00adfully. If you do not agree to be bound to each and every term and con\u00addi\u00adtion set forth herein, please exit the Site and do not access, read or oth\u00ader\u00adwise use infor\u00adma\u00adtion pro\u00advided herein. By access\u00ading the Site and/or read\u00ading its con\u00adtent, and/or using it to find infor\u00adma\u00adtion on any other web\u00adsite or infor\u00adma\u00adtional resource, you acknowl\u00adedge and agree that you have read and under\u00adstand these terms and con\u00addi\u00adtions, that the pro\u00advi\u00adsions, dis\u00adclo\u00adsures and dis\u00adclaimers set forth herein are fair and rea\u00adson\u00adable, and that your agree\u00adment to fol\u00adlow and be bound by these terms and con\u00addi\u00adtions is vol\u00adun\u00adtary and is not the result of fraud, duress or undue influ\u00adence exer\u00adcised upon you by any per\u00adson or entity.","title":"TERMS OF USE AGREEMENT:"},{"location":"about/#disclaimer-regarding-medical-advice","text":"The Principal author pro\u00advides the Site and anyser\u00advices, infor\u00adma\u00adtion, opinions, con\u00adtent, ref\u00ader\u00adences and links to other knowl\u00adedge resources (col\u00adlec\u00adtively, \u201cCon\u00adtent\u201d) for infor\u00adma\u00adtional pur\u00adposes only. The Author does not pro\u00advide any med\u00adical advice on the Site. Access\u00ading, read\u00ading or oth\u00ader\u00adwise using the Site does not cre\u00adate a physician-patient rela\u00adtion\u00adship between you and the Principal author. Pro\u00advid\u00ading per\u00adsonal or med\u00adical infor\u00adma\u00adtion to the Principal author does not cre\u00adate a physician-patient rela\u00adtion\u00adship between you and the Principal author or authors. Noth\u00ading con\u00adtained in the Site is intended to estab\u00adlish a physician-patient rela\u00adtion\u00adship, to replace the ser\u00advices of a trained physi\u00adcian or health care pro\u00adfes\u00adsional, or oth\u00ader\u00adwise to be a sub\u00adsti\u00adtute for pro\u00adfes\u00adsional med\u00adical advice, diag\u00adno\u00adsis, or treatment. You hereby agree that you shall not make any med\u00adical or health-related deci\u00adsion based in whole or in part on any\u00adthing con\u00adtained in the Site. You should not rely on any infor\u00adma\u00adtion con\u00adtained in the Site and related mate\u00adri\u00adals in mak\u00ading med\u00adical, health-related or other deci\u00adsions. You should con\u00adsult a licensed physi\u00adcian or appropriately-credentialed health care worker in your com\u00admu\u00adnity in all mat\u00adters relat\u00ading to your health.","title":"DISCLAIMER REGARDING MEDICAL ADVICE"},{"location":"about/#disclaimer-regarding-site-content-and-related-materials","text":"The Con\u00adtent may be changed with\u00adout notice and is not guar\u00adan\u00adteed to be com\u00adplete, cor\u00adrect, timely, cur\u00adrent or up-to-date. Sim\u00adi\u00adlar to any printed mate\u00adri\u00adals, the Con\u00adtent may become out-of-date. The Author under\u00adtakes no oblig\u00ada\u00adtion to update any Con\u00adtent on the Site. The Principal author may update the Con\u00adtent at any time with\u00adout notice, based on the Principal author\u2019s sole and absolute dis\u00adcre\u00adtion. The Principal author reserves the right to make alter\u00adations or dele\u00adtions to the Con\u00adtent at any time with\u00adout notice. Opin\u00adions expressed in the Site are not nec\u00ades\u00adsar\u00adily those of the Principal author or team. Any opin\u00adions of the Principal author have been con\u00adsid\u00adered in the con\u00adtext of cer\u00adtain con\u00addi\u00adtions and sub\u00adject to assump\u00adtions that can\u00adnot nec\u00ades\u00adsar\u00adily be applied to an indi\u00advid\u00adual case or par\u00adtic\u00adu\u00adlar cir\u00adcum\u00adstance. The Con\u00adtent may not and should not be used or relied upon for any other pur\u00adpose, includ\u00ading, but not lim\u00adited to, use in or in con\u00adnec\u00adtion with any legal proceeding. From time to time, the Site may con\u00adtain health\u2013 or medical-related infor\u00adma\u00adtion that is sex\u00adu\u00adally explicit. If you find this infor\u00adma\u00adtion offen\u00adsive, you may not want to use the Site.","title":"DISCLAIMER REGARDING SITE CONTENT AND RELATED MATERIALS"},{"location":"about/#disclaimer-regarding-third-party-links","text":"The Site may, from time to time, con\u00adtain links to other (\u201cthird party\u201d) web sites. These links are pro\u00advided solely as a con\u00adve\u00adnience and not as a guar\u00adan\u00adtee or rec\u00adom\u00admen\u00adda\u00adtion by the Principal author for the ser\u00advices, infor\u00adma\u00adtion, opin\u00adion or any other con\u00adtent on such third party web sites or as an indi\u00adca\u00adtion of any affil\u00adi\u00ada\u00adtion, spon\u00adsor\u00adship or endorse\u00adment of such third party web sites. If you decide to access a linked web\u00adsite, you do so at your own risk. Your use of other web\u00adsites is sub\u00adject to the terms of use for such sites. The Principal author is not respon\u00adsi\u00adble for the con\u00adtent of any linked or oth\u00ader\u00adwise con\u00adnected web sites. The Principal author does not make any rep\u00adre\u00adsen\u00adta\u00adtions or guar\u00adan\u00adtees regard\u00ading the pri\u00advacy prac\u00adtices of, or the con\u00adtent or accu\u00adracy of mate\u00adri\u00adals included in, any linked or third party web\u00adsites. The inclu\u00adsion of third party adver\u00adtise\u00adments on the Site does not con\u00adsti\u00adtute an endorse\u00adment, guar\u00adan\u00adtee, or rec\u00adom\u00admen\u00adda\u00adtion. The Principal author makes no rep\u00adre\u00adsen\u00adta\u00adtions and/or guar\u00adan\u00adtees regard\u00ading any prod\u00aduct or ser\u00advice con\u00adtained therein.","title":"DISCLAIMER REGARDING THIRD PARTY LINKS"},{"location":"about/#disclaimer-of-all-warranties","text":"Con\u00adtent made avail\u00adable at the Site is pro\u00advided on an \u201cas is\u201d and \u201cas avail\u00adable\u201d basis with\u00adout war\u00adranties of any kind, either express or implied. Under no cir\u00adcum\u00adstances, as a result of your use of the Site, will the Principal author be liable to you or to any other per\u00adson for any direct, indi\u00adrect, inci\u00adden\u00adtal, con\u00adse\u00adquen\u00adtial, spe\u00adcial, exem\u00adplary or other dam\u00adages under any legal the\u00adory, includ\u00ading, with\u00adout lim\u00adi\u00adta\u00adtion, tort, con\u00adtract, strict lia\u00adbil\u00adity or oth\u00ader\u00adwise, even if advised of the pos\u00adsi\u00adbil\u00adity of such damages.","title":"DISCLAIMER OF ALL WARRANTIES"},{"location":"about/#age-restriction","text":"The Site is intended for per\u00adsons eigh\u00adteen (18) years or older. Per\u00adsons under the age of eigh\u00adteen (18) should not access, use and/or browse the Site.","title":"AGE RESTRICTION"},{"location":"about/#indemnification","text":"You agree to indem\u00adnify and hold the Author harm\u00adless from any claim or demand, includ\u00ading attor\u00adneys\u2019 fees, made by any third party as a result of (1) any con\u00adtent posted or made avail\u00adable by you on this Site, (2) any vio\u00adla\u00adtion of law that occurs by you through the Site, and/or (3) any\u00adthing you do using the Site and/or the Con\u00adtent con\u00adtained therein.","title":"INDEMNIFICATION"},{"location":"about/#modification","text":"The Author may mod\u00adify the terms and con\u00addi\u00adtions of this Agree\u00adment in whole or in party at any time for any rea\u00adson with\u00adout any notice to you, based on her dis\u00adcre\u00adtion. Such mod\u00adi\u00adfied terms and con\u00addi\u00adtions shall super\u00adsede these terms and con\u00addi\u00adtions and shall become bind\u00ading when pub\u00adlished online on the Site.","title":"MODIFICATION"},{"location":"about/#entire-agreement","text":"You accept that this Agree\u00adment rep\u00adre\u00adsents the entire under\u00adstand\u00ading between you and the Author con\u00adcern\u00ading use of the Site.","title":"ENTIRE AGREEMENT"},{"location":"Biostatistics/","text":"Biostatistics Biostatistics is important for obvious reasons - to interpret collected data, derive conclusions, etc. Understanding Biostatistics is also important in its role of allowing a higher level interpretation and appraisal of research papers. Inappropriate use of statistical methods or poor practice methodology such as P-hacking may result in overestimation of an effect size - ultimately compromising the purpose of a research paper. Contents Medical Statistics This section outlines the content which is taught in a typical Introduction to Medical Statistics course at a tertiary level. The content in this basic course is unlikely to change, but it is useful for interpreting most research papers and most observational/cohort study designs. It is currently under development. My goal is currently to improve the mathematical rigor of these pages, as well as develop Python (jupyter, Google Colab) notebooks to be used with each chapter. Biostatistical Modelling This section includes topics in modelling of Biostatistical data. Modelling is important in two main aspects of medical research: Explanatory models - Explanatory models look at datasets to understand associations between predictor variables and outcome variables. Explanatory models in its simplest form are another approach to simple statistical approaches (such as OR, RR, etc.), however using models such as multivariate regression models allow control for confounding. They are generally more powerful models. Predictive models - Using a slightly different philosophy but the same mathematical approach, Predictive models create equations which can then be used in either diagnosis or prognosis of patients. Models such as the Framingham Risk Equation are predictive models based on survival regressions (e.g. Cox Proportional Hazards, Weibull Regression, etc.). Advanced Methods Advanced methods encompasses advanced statistical approaches to medical research, as well as areas of biostatistics that are still experimental (or not fully understood). This includes techniques such as Machine Learning, Individual Participant Data Meta-analysis, etc. Advanced methods should really only be used with an understanding of good biostatistical modelling skills.","title":"Introduction"},{"location":"Biostatistics/#biostatistics","text":"Biostatistics is important for obvious reasons - to interpret collected data, derive conclusions, etc. Understanding Biostatistics is also important in its role of allowing a higher level interpretation and appraisal of research papers. Inappropriate use of statistical methods or poor practice methodology such as P-hacking may result in overestimation of an effect size - ultimately compromising the purpose of a research paper.","title":"Biostatistics"},{"location":"Biostatistics/#contents","text":"Medical Statistics This section outlines the content which is taught in a typical Introduction to Medical Statistics course at a tertiary level. The content in this basic course is unlikely to change, but it is useful for interpreting most research papers and most observational/cohort study designs. It is currently under development. My goal is currently to improve the mathematical rigor of these pages, as well as develop Python (jupyter, Google Colab) notebooks to be used with each chapter. Biostatistical Modelling This section includes topics in modelling of Biostatistical data. Modelling is important in two main aspects of medical research: Explanatory models - Explanatory models look at datasets to understand associations between predictor variables and outcome variables. Explanatory models in its simplest form are another approach to simple statistical approaches (such as OR, RR, etc.), however using models such as multivariate regression models allow control for confounding. They are generally more powerful models. Predictive models - Using a slightly different philosophy but the same mathematical approach, Predictive models create equations which can then be used in either diagnosis or prognosis of patients. Models such as the Framingham Risk Equation are predictive models based on survival regressions (e.g. Cox Proportional Hazards, Weibull Regression, etc.). Advanced Methods Advanced methods encompasses advanced statistical approaches to medical research, as well as areas of biostatistics that are still experimental (or not fully understood). This includes techniques such as Machine Learning, Individual Participant Data Meta-analysis, etc. Advanced methods should really only be used with an understanding of good biostatistical modelling skills.","title":"Contents"},{"location":"Biostatistics/Advanced%20methods/","text":"","title":"Index"},{"location":"Biostatistics/Advanced%20methods/Data%20imputation/","text":"Data imputation Background Data imputation is used to deal with missing values - it is a method of filling missing data. Imputation can be undertaken as single imputation (the simplest form of imputation), as well as more complex methods. Simple imputation methods include: Mean imputation Regression imputation Regression imputation with noise Multiple imputation accounts for the fact that some data has been imputed, and aims to generate plausible imputed values. - Multiple imputation imputes multiple datasets with slightly different missing (imputed) values. This adds a level of uncertainty to the final dataset, reflecting the fact that we have imputed this data.","title":"Data imputation"},{"location":"Biostatistics/Advanced%20methods/Data%20imputation/#data-imputation","text":"","title":"Data imputation"},{"location":"Biostatistics/Advanced%20methods/Data%20imputation/#background","text":"Data imputation is used to deal with missing values - it is a method of filling missing data. Imputation can be undertaken as single imputation (the simplest form of imputation), as well as more complex methods. Simple imputation methods include: Mean imputation Regression imputation Regression imputation with noise Multiple imputation accounts for the fact that some data has been imputed, and aims to generate plausible imputed values. - Multiple imputation imputes multiple datasets with slightly different missing (imputed) values. This adds a level of uncertainty to the final dataset, reflecting the fact that we have imputed this data.","title":"Background"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/","text":"Missing Data Background In real datasets, we don't have all data available to us. Data can be missing for multiple reasons - e.g.: Loss to follow-up Participant doesn't answer the question Participant didn't know how to answer the question The issue with this is that if we remove this data, we lose power in the study (as we lose a lot of data which could otherwise be used) What to do with missing data Complete case analysis Data imputation Assessing missing data Missing data needs to first be assessed first before we do anything to it. We need to consider the question: Why the data is missing in the first place? . The missing-ness of data can be classified in three ways: Missing completely at random (MCAR) Missing at random (MAR) Missing NOT at random (MNAR) Missing completely at random (MCAR) This is the best form of missingness - it means that the data is missing completely by chance. The reason for missingness is not due to any issue consistent within the population . This type of randomness has a similar distribution to if we selected a completely random sample of individuals from the population, and deleted some of their data. With this type of missingness, you should have a valid complete case analysis (i.e. the results should be similar), however the only issue with a complete case analysis is a reduction in power. Missing data is almost never missing at random. Missing at random (MAR) Missing at random implies that the missingness is dependent on another variable observed - there is some relationship between this variable and another variable. For example, if we collect data including age, exercise tolerance, etc. and find that exercise tolerance data appears to be missing more commonly in older individuals (perhaps they are embarassed?), then we would say this data is missing at random (However not completely at random). One way of describing this could be 'missing conditionally at random' - where there is a presupposed condition that is observed (in this case older individuals), which makes missingness more common, however the actual observations which are missing are still random. This is the type of data which is best dealt with using imputation. Missing not at random (MNAR) This is missingness dependent on another variable not observed . Examples include Data missing in sicker patients, but we have not measured health status Smoking status not recorded on emergency presentation, however this group of people appear to have worse surgical outcomes The only way to properly determine if missingness is MNAR is by collecting data that is missing - however this is not usuallyh achievable. Dealing with missing data Complete case analysis Complete case analysis can bias our results in the wrong situation. This approach works by us completely removing any collected data with missing variables (i.e. all we have remaining are complete cases ). If there are very few observations with missing variables, this is not actually a big deal! It only becomes problematic when a large proportion of the original data is missing. Imputation see Data imputation References finalfit R package documentation \"Missing data\" - Ewen Harrison PUBH5218 - Advanced Statistical Modelling Semester 1 2021 (University of Sydney), Week 4. Missing Data","title":"Missing Data"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#missing-data","text":"","title":"Missing Data"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#background","text":"In real datasets, we don't have all data available to us. Data can be missing for multiple reasons - e.g.: Loss to follow-up Participant doesn't answer the question Participant didn't know how to answer the question The issue with this is that if we remove this data, we lose power in the study (as we lose a lot of data which could otherwise be used) What to do with missing data Complete case analysis Data imputation","title":"Background"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#assessing-missing-data","text":"Missing data needs to first be assessed first before we do anything to it. We need to consider the question: Why the data is missing in the first place? . The missing-ness of data can be classified in three ways: Missing completely at random (MCAR) Missing at random (MAR) Missing NOT at random (MNAR)","title":"Assessing missing data"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#missing-completely-at-random-mcar","text":"This is the best form of missingness - it means that the data is missing completely by chance. The reason for missingness is not due to any issue consistent within the population . This type of randomness has a similar distribution to if we selected a completely random sample of individuals from the population, and deleted some of their data. With this type of missingness, you should have a valid complete case analysis (i.e. the results should be similar), however the only issue with a complete case analysis is a reduction in power. Missing data is almost never missing at random.","title":"Missing completely at random (MCAR)"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#missing-at-random-mar","text":"Missing at random implies that the missingness is dependent on another variable observed - there is some relationship between this variable and another variable. For example, if we collect data including age, exercise tolerance, etc. and find that exercise tolerance data appears to be missing more commonly in older individuals (perhaps they are embarassed?), then we would say this data is missing at random (However not completely at random). One way of describing this could be 'missing conditionally at random' - where there is a presupposed condition that is observed (in this case older individuals), which makes missingness more common, however the actual observations which are missing are still random. This is the type of data which is best dealt with using imputation.","title":"Missing at random (MAR)"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#missing-not-at-random-mnar","text":"This is missingness dependent on another variable not observed . Examples include Data missing in sicker patients, but we have not measured health status Smoking status not recorded on emergency presentation, however this group of people appear to have worse surgical outcomes The only way to properly determine if missingness is MNAR is by collecting data that is missing - however this is not usuallyh achievable.","title":"Missing not at random (MNAR)"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#dealing-with-missing-data","text":"","title":"Dealing with missing data"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#complete-case-analysis","text":"Complete case analysis can bias our results in the wrong situation. This approach works by us completely removing any collected data with missing variables (i.e. all we have remaining are complete cases ). If there are very few observations with missing variables, this is not actually a big deal! It only becomes problematic when a large proportion of the original data is missing.","title":"Complete case analysis"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#imputation","text":"see Data imputation","title":"Imputation"},{"location":"Biostatistics/Advanced%20methods/Missing%20Data/#references","text":"finalfit R package documentation \"Missing data\" - Ewen Harrison PUBH5218 - Advanced Statistical Modelling Semester 1 2021 (University of Sydney), Week 4. Missing Data","title":"References"},{"location":"Biostatistics/Advanced%20methods/Missing%20values/","text":"Missing values See Approach to missing values for a practical approach to dealing with missing values Background Distribution of missing-ness Dealing with missing values See Data imputation https://www.lshtm.ac.uk/research/centres-projects-groups/missing-data","title":"Missing values"},{"location":"Biostatistics/Advanced%20methods/Missing%20values/#missing-values","text":"See Approach to missing values for a practical approach to dealing with missing values","title":"Missing values"},{"location":"Biostatistics/Advanced%20methods/Missing%20values/#background","text":"","title":"Background"},{"location":"Biostatistics/Advanced%20methods/Missing%20values/#distribution-of-missing-ness","text":"","title":"Distribution of missing-ness"},{"location":"Biostatistics/Advanced%20methods/Missing%20values/#dealing-with-missing-values","text":"See Data imputation https://www.lshtm.ac.uk/research/centres-projects-groups/missing-data","title":"Dealing with missing values"},{"location":"Biostatistics/Advanced%20methods/Advanced%20biostatistical%20modelling/","text":"References - https://bookdown.org/roback/bookdown-BeyondMLR/","title":"Index"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Advanced%20methods%20in%20meta-analysis/","text":"Advanced methods in meta-analysis With more research into clinical epidemiology and meta-analysis methods, some new methods have been developed (and are currently in development). This includes Network meta-analysis Network meta-analysis allows comparisons to occur between different treatments. Say you had a series of studies comparing bupivicaine and lignocaine for local analgesia, and then a series of studies comparing lignocaine against lignocaine with adrenaline. How would you then compare bupivicaine with lignocaine + adrenaline? More theoretically, say you had study A vs B, and study B vs C - network meta-analysis will enable you to compare A vs C. Living meta-analysis A living meta-analysis is a special form of (experimental) meta-analysis which constantly updates. Its use has become more common during COVID-19 with increasing number of experimental treatments and reported studies, but with limited clinical guidelines/direction. Individual participant data (IPD) meta-analysis An area of research in meta-analysis focusing on the analysing pooled individual trial datasets.","title":"Advanced methods in meta-analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Advanced%20methods%20in%20meta-analysis/#advanced-methods-in-meta-analysis","text":"With more research into clinical epidemiology and meta-analysis methods, some new methods have been developed (and are currently in development). This includes Network meta-analysis Network meta-analysis allows comparisons to occur between different treatments. Say you had a series of studies comparing bupivicaine and lignocaine for local analgesia, and then a series of studies comparing lignocaine against lignocaine with adrenaline. How would you then compare bupivicaine with lignocaine + adrenaline? More theoretically, say you had study A vs B, and study B vs C - network meta-analysis will enable you to compare A vs C. Living meta-analysis A living meta-analysis is a special form of (experimental) meta-analysis which constantly updates. Its use has become more common during COVID-19 with increasing number of experimental treatments and reported studies, but with limited clinical guidelines/direction. Individual participant data (IPD) meta-analysis An area of research in meta-analysis focusing on the analysing pooled individual trial datasets.","title":"Advanced methods in meta-analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Individual%20Participant%20Data%20Meta-analysis/","text":"","title":"Individual Participant Data Meta analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Living%20meta-analysis/","text":"","title":"Living meta analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Meta-Regression/","text":"","title":"Meta Regression"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/","text":"Network meta-analysis Terminology Terminology for meta-analysis: Order The order of the network meta-analysis indicates the number of treatment arms included in this meta-analysis. For example, an order \\(N\\) meta-analysis has \\(N+2\\) treatment arms. A 'triangular meta-analysis' is of order \\(1\\) . This means there are 3 treatment arms (A, B and C). Data extraction DECiMAL (Data Extration for Complex Meta-analysis) Example data extraction For multivariate, and network meta-analysis information Key items for data extraction Bibliographic information (e.g. study ID) Trial characteristics Patient characteristics (for study level and arm level) Intervention and comparator(s) Outcomes (continuous vs. binary, aggregate measures vs. 2x2 table, end of study vs. change values) Risk of Bias Don't use covidence, etc. if you are trying to pool a network meta-analysis Notes: Quality control and data cleaning are critical (e.g. incorrectly placed decimals could stop the whole process!) Network meta-analyses could end up with hundreds of data points - you NEED to systematically look for mistakes Do descriptive statistics (e.g. Mean, IQR, etc.) to make sure your numbers aren't off If you are not sure between SD and SE, contact the authors to make sure - SE is typically very small compared to SD - unless it is specified, take care! Data extraction formats Conventional vs. network meta-analysis Conventional: Wide format (one row per study), multiple worksheets (for each study) Wide format (one row per study), one worksheet Compact wide format (one row per study), one worksheet Long format (one row per arm) - preferred format for NMA Preparing data for NMA Count data Command in Stata: network setup eventvar nvar [if] [in], studyvar(varname) trtvar(varname) [or|rr|rd|hr zeroadd(#)] ref(string) Default is OR Continuous data: Command in Stata: network setup meanvar sdvar nvar [if] [in], trtvar(varname) studyvar(varname) [md|smd] ref(string) Default is SMD Software will automatically do continuity corrections (e.g. 0 in certain arms). You can also tell the study which study is your reference - whilst different results should give the same result, choosing a reference treatment to be central in the network (the better-connected treatment) may improve numerical stability. Usually placebo/no treatment is the reference, but you might want to pick a treatment arm. Assumptions of indirect comparisons Homogeneity assumption Undertaken using \\(I^2\\) , Cochran Q test, P-value for signifiance. An \\(I^2 = 0\\) means there is no statistical heterogeneity, but there might be a conceptual heterogeneity. Transivity Assumption (Similarity assumption) - extra for NMA Similar to conceptual heterogeneity. If you have drug A having a common comparator to B and C - if AB is cross-over and AC is parallel design, this violates transivity assumption of methodology. If A vs B uses Visual analogue scale, and A vs C uses a McGill pain questionnaire, this could violate transivity assumption. If A is 'weight watcher' and B is 'Dash diet' and C is 'Mediterranean diet', and every study in A vs B receieves counseling, but all studies A vs C didn't use counseling - this cointervention can change the treatment, and so it is a violation of the transivitity assumption. Transivity assumption applies to: Patients - e.g. patients of different ages between interventions Be careful when considering patients - you shouldn't rely on Table 1 patient distributions to determine transivity (e.g. consideration of age). Transitivity isn't black and white - there will always be differences in patient backgrounds. It is up to you to determine HOW MUCH and HOW MUCH WILL IT MATTER, rather than yes/no. Co-interventions Outcomes Methodology Note there is NO WAY to test for transivity, it depends on your own judgement (do you think there is a fundamental difference between the trials?) Coherence assumption (Similarity assumption) Can be assessed pairwise, loop-specific, and in-network. The assumption is STATISTIC (p-value attached to it). Statistical approaches for Indirect Treatment Comparisons (ITC) ITCs are not new. Bucher et al. (1997) demonstrated the simplest form. The process is as follows: Given odds ratio of study 1) (A vs B) and study 2) (A vs C), and you want to determine how B compares against C:A vs. C and number of studies B vs. C: Calculate the log(OR(A vs B)) and log(OR(A vs C)) Calculate log(OR(A vs B)) : log(OR(A vs C)) If this ratio > 1 \\(\\rightarrow\\) , B is better than C. This method is the simpliest approach to a triangular meta-analysis. If you are going over loop of 3, and don't construct a connected network, it becomes a adjusted indirect treatment comparison (rather than simply ITC). Assumptions for each level of multiple treatment comparison Homogeneity assumption in pairwise function Ensure there is no considerable heterogeneity in each pairwise comparison Homogeneity and similarity of trial Check similarity or transitivity assumption in loops. What if I have multiple interventions NOT in a loop? Consider the following study - imagine we were assessing the effect of different interventions on smoking cessation. In our first order loop ('triangle' loop), we: Directly compare the effect of NRT vs Anti-depressants The meta-analysis here involves 3 trials, demonstrating OR of 1.34 (0.71 - 2.56) with \\(I^2 = 0.437\\) Indirectly compare NRT to control and Anti-depressants to control The meta-analysis of NRT vs control is equal to 1.85, \\(I^2 = 0.13\\) involving 67 comparisons. The meta-analysis of Antidepressants vs control is equal to 1.88, \\(I^2 = 0.19\\) , involving 29 comparisons. When undertaking simple ITC, we get the indirect score of 1.01 (0.81 - 0.127). This network actually has another second order loop which compares antidepressant vs NRT as well. For this, we can ALSO calculate the direct and indirect comparisons. In fact, there are a NUMBER of different loops involving NRT and Anti-depressants. In this example, there are five separate loops involving anti-depressants vs NRT. How do we then calculate the network effect? The network effect is calculated by undertaking a simple meta-analysis of the calculated indirect loops . This will be affected by: The order of the loop - lower loops have higher weight The standard error of the indirect effect ( \\(weight = \\frac{1}{SE}\\) ) By pooling the direct and pooled-indirect estimates, you can calculate the network estimate. The relative weighting of the direct and pool-indirect estimates is calculated on a contribution table (or contribution plot). Useful to check when doing GRADE assessments. Other statistical approaches to network meta-analysis Frequentist framework Bayestian framework - more popular for analysis of published networks Philosophically, frequentist and bayesian approaches are different statistical approaches. Both are concerned with parameter estimation (inference of something about a population taken from a sample). From a probabilistic perspective, we don't know what the parameter is - as we can't find a point estimate, we also need to come up with a distribution (i.e. the 95% confidence interval). These frameworks approach distributions differently. However, Empirical and simulation studies have shown NMAs from frequentist models do not differ from Bayesian models with vague(flat/uninformative) priors. Bayesian framework for NMA Look at probability in a general way - yes the probability is unknown, but we can use a probability to represent the uncertainty in this value. Example - looking at height: I agree that the mean is a fixed and known value, but i know it is not 0 and it is not 50cm, I know it cannot be >3m. I know there is no issue with calculating the uncertainty through a probabilistic means. I can come up with a probability but imaginative distribution of height in this population. I will use 1+ samples from this population, have an estimate and 95% CI, and also a probability distribution regarding what comes out of the sample. Bayesian models have more flexibility: - informative vs. vague priors for effect estimates - Vague prior = very wide normal distribution, which captures every possibility in a priori distribution/parameter. Very wide distribution from 0 to infinity, but we know it is normally distributed - semi-informative prior = noting the probability that the distribution is going to be from 20cm to 1000cm in height - there is still a wide range of values, but our approach is still semi-informative (not 0 to infinity). We still assume a normal shaped distribution - Fully-informative priors = still attached to a credible interval, but the values are more informed by previous studies (i.e. there is evidence to support the range of values/intervals) - Informative priors requires justification - Arm-based model vs. Contrast-based model - Able to look into effect modifications at arm-level covariates in arm-based models compared to contrast-based models - Arm based model advantage - covariate/intervention/effect modifier affecting arm-level estimates, and I want to adjust for that arm-level value. - Assumption: Prognostic factors are distributed equally if randomisation is done correctly between trial arms - usually, it is unrealistic to think there is effect modification for a prognostic factor at arm level - as a result, Arm-level NMA is not usually different from Contrast-based models - Variable between-study variances (heterogeneity) vs. common between-study variance - frequentists normally use common between-study variance for heterogeneity. - Say you have 13 intervention and 25 comparisons, - each comparison has a heterogeneity estimate ( \\(I^2\\) estimate) - the estimate of heterogeneity is different - In frequentist NMA, there is typically a single heterogeneity estimate for the whole network - DIC (deviance information criteria) and \\(D_{hat}\\) statistics (model fit) provide information regarding whether you picked the right model. This is only available to Bayesian models, and is a benefit of the flexibility. - Fixed vs. Random effects - Consistency vs. inconsistence - Network meta-regression vs NMA Frequentist framework for NMA Do not attach a-priori probability to hypothesis regarding parameter in the population. We know it is a fixed value, but we don't know what it is. Example - looking at height I don't know the mean value of height in the female population I know this value is FIXED and NOT RANDOM - I can use a sample population and estimate the mean from the sample, which will give me a probability distribution of this mean. I will use 1+ samples from this population and come up with an estimate and 95% CI around the estimate References These notes were made based on: Behnam Sadeghirad's youtube videos Video 1 , Video 2 , Video 3 and Video 4 Cochrane handbook chapter 11 (Network meta-analysis) here Cochrane network meta-analysis learning modules here","title":"Network meta-analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#network-meta-analysis","text":"","title":"Network meta-analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#terminology","text":"Terminology for meta-analysis: Order The order of the network meta-analysis indicates the number of treatment arms included in this meta-analysis. For example, an order \\(N\\) meta-analysis has \\(N+2\\) treatment arms. A 'triangular meta-analysis' is of order \\(1\\) . This means there are 3 treatment arms (A, B and C).","title":"Terminology"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#data-extraction","text":"DECiMAL (Data Extration for Complex Meta-analysis) Example data extraction For multivariate, and network meta-analysis information","title":"Data extraction"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#key-items-for-data-extraction","text":"Bibliographic information (e.g. study ID) Trial characteristics Patient characteristics (for study level and arm level) Intervention and comparator(s) Outcomes (continuous vs. binary, aggregate measures vs. 2x2 table, end of study vs. change values) Risk of Bias Don't use covidence, etc. if you are trying to pool a network meta-analysis Notes: Quality control and data cleaning are critical (e.g. incorrectly placed decimals could stop the whole process!) Network meta-analyses could end up with hundreds of data points - you NEED to systematically look for mistakes Do descriptive statistics (e.g. Mean, IQR, etc.) to make sure your numbers aren't off If you are not sure between SD and SE, contact the authors to make sure - SE is typically very small compared to SD - unless it is specified, take care!","title":"Key items for data extraction"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#data-extraction-formats","text":"Conventional vs. network meta-analysis Conventional: Wide format (one row per study), multiple worksheets (for each study) Wide format (one row per study), one worksheet Compact wide format (one row per study), one worksheet Long format (one row per arm) - preferred format for NMA","title":"Data extraction formats"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#preparing-data-for-nma","text":"Count data Command in Stata: network setup eventvar nvar [if] [in], studyvar(varname) trtvar(varname) [or|rr|rd|hr zeroadd(#)] ref(string) Default is OR Continuous data: Command in Stata: network setup meanvar sdvar nvar [if] [in], trtvar(varname) studyvar(varname) [md|smd] ref(string) Default is SMD Software will automatically do continuity corrections (e.g. 0 in certain arms). You can also tell the study which study is your reference - whilst different results should give the same result, choosing a reference treatment to be central in the network (the better-connected treatment) may improve numerical stability. Usually placebo/no treatment is the reference, but you might want to pick a treatment arm.","title":"Preparing data for NMA"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#assumptions-of-indirect-comparisons","text":"Homogeneity assumption Undertaken using \\(I^2\\) , Cochran Q test, P-value for signifiance. An \\(I^2 = 0\\) means there is no statistical heterogeneity, but there might be a conceptual heterogeneity. Transivity Assumption (Similarity assumption) - extra for NMA Similar to conceptual heterogeneity. If you have drug A having a common comparator to B and C - if AB is cross-over and AC is parallel design, this violates transivity assumption of methodology. If A vs B uses Visual analogue scale, and A vs C uses a McGill pain questionnaire, this could violate transivity assumption. If A is 'weight watcher' and B is 'Dash diet' and C is 'Mediterranean diet', and every study in A vs B receieves counseling, but all studies A vs C didn't use counseling - this cointervention can change the treatment, and so it is a violation of the transivitity assumption. Transivity assumption applies to: Patients - e.g. patients of different ages between interventions Be careful when considering patients - you shouldn't rely on Table 1 patient distributions to determine transivity (e.g. consideration of age). Transitivity isn't black and white - there will always be differences in patient backgrounds. It is up to you to determine HOW MUCH and HOW MUCH WILL IT MATTER, rather than yes/no. Co-interventions Outcomes Methodology Note there is NO WAY to test for transivity, it depends on your own judgement (do you think there is a fundamental difference between the trials?) Coherence assumption (Similarity assumption) Can be assessed pairwise, loop-specific, and in-network. The assumption is STATISTIC (p-value attached to it).","title":"Assumptions of indirect comparisons"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#statistical-approaches-for-indirect-treatment-comparisons-itc","text":"ITCs are not new. Bucher et al. (1997) demonstrated the simplest form. The process is as follows: Given odds ratio of study 1) (A vs B) and study 2) (A vs C), and you want to determine how B compares against C:A vs. C and number of studies B vs. C: Calculate the log(OR(A vs B)) and log(OR(A vs C)) Calculate log(OR(A vs B)) : log(OR(A vs C)) If this ratio > 1 \\(\\rightarrow\\) , B is better than C. This method is the simpliest approach to a triangular meta-analysis. If you are going over loop of 3, and don't construct a connected network, it becomes a adjusted indirect treatment comparison (rather than simply ITC).","title":"Statistical approaches for Indirect Treatment Comparisons (ITC)"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#assumptions-for-each-level-of-multiple-treatment-comparison","text":"Homogeneity assumption in pairwise function Ensure there is no considerable heterogeneity in each pairwise comparison Homogeneity and similarity of trial Check similarity or transitivity assumption in loops.","title":"Assumptions for each level of multiple treatment comparison"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#what-if-i-have-multiple-interventions-not-in-a-loop","text":"Consider the following study - imagine we were assessing the effect of different interventions on smoking cessation. In our first order loop ('triangle' loop), we: Directly compare the effect of NRT vs Anti-depressants The meta-analysis here involves 3 trials, demonstrating OR of 1.34 (0.71 - 2.56) with \\(I^2 = 0.437\\) Indirectly compare NRT to control and Anti-depressants to control The meta-analysis of NRT vs control is equal to 1.85, \\(I^2 = 0.13\\) involving 67 comparisons. The meta-analysis of Antidepressants vs control is equal to 1.88, \\(I^2 = 0.19\\) , involving 29 comparisons. When undertaking simple ITC, we get the indirect score of 1.01 (0.81 - 0.127). This network actually has another second order loop which compares antidepressant vs NRT as well. For this, we can ALSO calculate the direct and indirect comparisons. In fact, there are a NUMBER of different loops involving NRT and Anti-depressants. In this example, there are five separate loops involving anti-depressants vs NRT. How do we then calculate the network effect? The network effect is calculated by undertaking a simple meta-analysis of the calculated indirect loops . This will be affected by: The order of the loop - lower loops have higher weight The standard error of the indirect effect ( \\(weight = \\frac{1}{SE}\\) ) By pooling the direct and pooled-indirect estimates, you can calculate the network estimate. The relative weighting of the direct and pool-indirect estimates is calculated on a contribution table (or contribution plot). Useful to check when doing GRADE assessments.","title":"What if I have multiple interventions NOT in a loop?"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#other-statistical-approaches-to-network-meta-analysis","text":"Frequentist framework Bayestian framework - more popular for analysis of published networks Philosophically, frequentist and bayesian approaches are different statistical approaches. Both are concerned with parameter estimation (inference of something about a population taken from a sample). From a probabilistic perspective, we don't know what the parameter is - as we can't find a point estimate, we also need to come up with a distribution (i.e. the 95% confidence interval). These frameworks approach distributions differently. However, Empirical and simulation studies have shown NMAs from frequentist models do not differ from Bayesian models with vague(flat/uninformative) priors.","title":"Other statistical approaches to network meta-analysis"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#bayesian-framework-for-nma","text":"Look at probability in a general way - yes the probability is unknown, but we can use a probability to represent the uncertainty in this value. Example - looking at height: I agree that the mean is a fixed and known value, but i know it is not 0 and it is not 50cm, I know it cannot be >3m. I know there is no issue with calculating the uncertainty through a probabilistic means. I can come up with a probability but imaginative distribution of height in this population. I will use 1+ samples from this population, have an estimate and 95% CI, and also a probability distribution regarding what comes out of the sample. Bayesian models have more flexibility: - informative vs. vague priors for effect estimates - Vague prior = very wide normal distribution, which captures every possibility in a priori distribution/parameter. Very wide distribution from 0 to infinity, but we know it is normally distributed - semi-informative prior = noting the probability that the distribution is going to be from 20cm to 1000cm in height - there is still a wide range of values, but our approach is still semi-informative (not 0 to infinity). We still assume a normal shaped distribution - Fully-informative priors = still attached to a credible interval, but the values are more informed by previous studies (i.e. there is evidence to support the range of values/intervals) - Informative priors requires justification - Arm-based model vs. Contrast-based model - Able to look into effect modifications at arm-level covariates in arm-based models compared to contrast-based models - Arm based model advantage - covariate/intervention/effect modifier affecting arm-level estimates, and I want to adjust for that arm-level value. - Assumption: Prognostic factors are distributed equally if randomisation is done correctly between trial arms - usually, it is unrealistic to think there is effect modification for a prognostic factor at arm level - as a result, Arm-level NMA is not usually different from Contrast-based models - Variable between-study variances (heterogeneity) vs. common between-study variance - frequentists normally use common between-study variance for heterogeneity. - Say you have 13 intervention and 25 comparisons, - each comparison has a heterogeneity estimate ( \\(I^2\\) estimate) - the estimate of heterogeneity is different - In frequentist NMA, there is typically a single heterogeneity estimate for the whole network - DIC (deviance information criteria) and \\(D_{hat}\\) statistics (model fit) provide information regarding whether you picked the right model. This is only available to Bayesian models, and is a benefit of the flexibility. - Fixed vs. Random effects - Consistency vs. inconsistence - Network meta-regression vs NMA","title":"Bayesian framework for NMA"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#frequentist-framework-for-nma","text":"Do not attach a-priori probability to hypothesis regarding parameter in the population. We know it is a fixed value, but we don't know what it is. Example - looking at height I don't know the mean value of height in the female population I know this value is FIXED and NOT RANDOM - I can use a sample population and estimate the mean from the sample, which will give me a probability distribution of this mean. I will use 1+ samples from this population and come up with an estimate and 95% CI around the estimate","title":"Frequentist framework for NMA"},{"location":"Biostatistics/Advanced%20methods/Advanced%20meta-analysis/Network%20meta-analysis/#references","text":"These notes were made based on: Behnam Sadeghirad's youtube videos Video 1 , Video 2 , Video 3 and Video 4 Cochrane handbook chapter 11 (Network meta-analysis) here Cochrane network meta-analysis learning modules here","title":"References"},{"location":"Biostatistics/Advanced%20methods/Data%20simulation/Data%20Simulation/","text":"Data Simulation References https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-015-0055-5 Packages https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html","title":"Data Simulation"},{"location":"Biostatistics/Advanced%20methods/Data%20simulation/Data%20Simulation/#data-simulation","text":"","title":"Data Simulation"},{"location":"Biostatistics/Advanced%20methods/Data%20simulation/Data%20Simulation/#references","text":"https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-015-0055-5","title":"References"},{"location":"Biostatistics/Advanced%20methods/Data%20simulation/Data%20Simulation/#packages","text":"https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html","title":"Packages"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/AutoRegressive%20Models/","text":"AutoRegressive models Note: An associated jupyter file has been created to follow along with for learning purposes.","title":"AutoRegressive models"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/AutoRegressive%20Models/#autoregressive-models","text":"Note: An associated jupyter file has been created to follow along with for learning purposes.","title":"AutoRegressive models"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/","text":"Introduction to Time Series Analysis Background Forecasting is used in econometric models. Examples of other forecasting models include linear regression -type models. In regression models, the general form is \\(y=a+bx\\) - in these models, we might not always have the relevant variables to do the forecasting. We might only have \\(y\\) -values for certain time periods, but we might lack the explanatory covariates \\(x\\) . Where covariates are unavailable, and time is the only variable available, then this is when we use time-series forecasting. We look at how time affects the outcome \\(y\\) . What is a time series? A series of data taken at different points in time. Examples include: - Stock prices of a single stock across various time periods By its definition, time series data cannot be cross-sectional data This data may be collected at regular time periods (i.e. the interval between collecting data is exactly the same - \\(t_2 - t_1 = t_1 - t_0\\) ) Forms of time series Univariate Time series Time series consisting of single observations over regular time intervals - for example, monthly returns data of a stock. Aim is to use past values of series data to predict future values - e.g. stocks, GDP, sales data e.g. forecasting inflation, unemployment rates, exchange rates, product demands, interest rates Multivariate Time series Emerging patterns Depending on the frequency of data collection, we have different resolutions in our data - this allows for different patterns to emerge from the same situation (with differently collected data frequencies). Some example emerging patterns which may be observed: Trend data Upward or downward sloping long term direction persisting Seasonal data E.g. sales data Related to seasonal natural or human behaviour Cyclic data Pattern may last > 1 year Series follow up- and down- variations that are not seasonal E.g. budget patterns - might change across multiple years, resulting from recession/inflation - would expect to see a wave-like pattern Cycles may not necessarily be regular Random data Any data with no particular pattern - cannot be explained Irregularities Could be due to one-off issues occuring in data collection Stationarity A \"strictly stationary\" series is if the marginal distribution of \\(Y\\) at time \\(t[p(Y_t)]\\) is the same as at any other point in time. Therefore \\(p(Y_t) = p(Y_{t+k})\\) and \\(p(Y_t, Y_{t+k})\\) does not depend on \\(t\\) , where \\(t\\ge1\\) and \\(k\\) is any integer. This implies that mean, variance of covariant of series \\(Y_t\\) are time invariant A series is \"weakly stationary\" or \"covariance stationary\" if the following conditions are met: \\(E(Y_1) = E(Y_2) = E(Y_3) = ... = E(Y_t) = \\mu(constant)\\) \\(Var(Y_1) = Var(Y_2) = Var(Y_3) = ... = Var(Y_t) = \\gamma_0 (constant)\\) \\(Cov(Y_1, Y_{1+k}) = Cov(Y_2, Y_{2+k}) = Cov(Y_3, Y_{3+k}) = \\gamma_k\\) depending only on lag \\(k\\) . Stationarity assumption Estimation and forecasting methods The Box-Jenkins (B-J) methodology is used to estimate and forecast univariate time-series models. This includes the steps: Identification Autocorrelation function (ACF) Autocorrelation refers to how observations in a time series are related to each other, and is measured by a correlation between the current observation \\(Y_t\\) and the observation \\(p\\) periods from the current one \\(Y_{t-p}\\) . \\(\\rho_k = Corr(Y_t, Y_{t-p}) = \\frac{Cov(Y_t, Y_{t-p})}{\\sqrt{var(Y_t)}\\sqrt{var(Y_{t-p})}} = \\frac{\\gamma_p}{\\gamma_0}\\) Partial autocorrelation function (PACF) Partial autocorrelations are used to measure the degree of association between \\(Y_t\\) and \\(Y_{t-p}\\) when the effects at other time lags \\(1, 2, 3, ..., (p-1)\\) are removed - essentially like the ACF but we remove a few of the intermediate values. Inference from ACF and PACF Theoretical ACF and PACFs are available for various values of the lags of autoregressive and moving average components - e.g. \\(p\\) and \\(q\\) . A comparison of the correlograms (plot of sample ACFs vs. lags) of the time series data with theoretical ACFs and PACFs leads to the selection of the appropriate ARIMA \\((p, q)\\) model. Estimation Estimation methods usually determined by software Yule-Walker procedure Method of moments Maximum likelihood method Diagnostic checking Lowest value of AIC/BIC/SBIC - choose model with the lowest value of the criterion Plot the residual ACF - expect random residuals This method can only be applied to stationary series/variables. If the model is not stationary, you must differentiate and make the dataset stationary. Time series processes and models White noise A time series is 'white noise' if it is purely random in nature. Let \\(\\epsilon_t\\) denote such a series. Then it has a zero mean \\(E(\\epsilon_t) = 0\\) , a constant variance \\(V(\\epsilon_t) = \\sigma^2\\) , and is an uncorrelated random variable \\(E(\\epsilon_t \\epsilon_s) = 0\\) . The scatter plot of such a plot will indicate no pattern - forecasting future values of such a series is not possible. i.e. STOP DOING TIME SERIES FORECASTING - it will be pointless The best forecast available for white noise is its average AutoRegressive (AR) models AutoRegressive (AR) models involve forecasting performed only on its own past values. That is, for a prediction \\(Y_t\\) , the forecast function is given as \\(Y_t = f(Y_{t-1}, Y_{t-2}, Y_{t-3}, ..., \\epsilon_t)\\) The question in these models is when do we stop taking past values (i.e. how many values of past \\(Y\\) should we take?) The general form is given by: \\(Y_t = \\beta_0 + \\beta_1Y_{t-1}+\\beta_2Y_{t-2}+\\beta_3Y_{t-3} + ... + \\beta_pY_{t-p}+\\epsilon_t\\) Moving Average (MA) model Moving average (MA) models involve forecasting by error terms - Consider forecasting each time-series point using its previous point: \\(Y_t = Y_{t-1} + \\beta_0 + \\epsilon_1\\) \\(Y_{t-1} = Y_{t-2} + \\beta_1 + \\epsilon_2\\) \\(Y_{t-2} = Y_{t-3} + \\beta_2 + \\epsilon_3\\) We would expect that the error terms \\(\\epsilon\\) are effectively white noise processes and have a mean of \\(0\\) and variance \\(\\sigma^2\\) (a constant). In the moving average (MA) model, we form a function on the error terms: \\(Y_t = \\beta_0 + \\epsilon_t + \\Phi_1\\epsilon_{t-1}+\\Phi_2\\epsilon_{t-2}+\\Phi_3\\epsilon_{t-3}+...+\\Phi_q\\epsilon_{t-q}\\) AutoRegressive Moving Average (ARMA) model People believe this model is more accurate than simple AutoRegressive or Moving Average models individually. The ARMA model depends on \\(p\\) , its own past values and \\(q\\) , the past values of white noise disturbances. The general formula takes the form: \\(Y_t = \\beta_0 + \\beta_1Y_{t-1}+\\beta_2Y_{t-2}+\\beta_3Y_{t-3}+...+\\beta_pY_{t-p}+\\epsilon_t+\\Phi_1\\epsilon_{t-1}+\\Phi_2\\epsilon_{t-2}+\\Phi_3\\epsilon_{t-3}+...+\\Phi_q\\epsilon_{t-q}\\) AutoRegressive Integrating Moving Average (ARIMA) model ARIMA models are applied to models with non-stationary series. A series which is stationary after being differentiated once is to be integrated of order 1, denoted \\(I(1)\\) . In its general form, a series which is stationary after being differentiated \\(d\\) times is denoted \\(I(d)\\) . A stationary series without differentiating is denoted \\(I(0)\\) . ARCH Garch ECM Panel data model References Youtube - Analytics University - https://www.youtube.com/watch?v=Aw77aMLj9uM","title":"Introduction to Time Series Analysis"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#introduction-to-time-series-analysis","text":"","title":"Introduction to Time Series Analysis"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#background","text":"Forecasting is used in econometric models. Examples of other forecasting models include linear regression -type models. In regression models, the general form is \\(y=a+bx\\) - in these models, we might not always have the relevant variables to do the forecasting. We might only have \\(y\\) -values for certain time periods, but we might lack the explanatory covariates \\(x\\) . Where covariates are unavailable, and time is the only variable available, then this is when we use time-series forecasting. We look at how time affects the outcome \\(y\\) .","title":"Background"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#what-is-a-time-series","text":"A series of data taken at different points in time. Examples include: - Stock prices of a single stock across various time periods By its definition, time series data cannot be cross-sectional data This data may be collected at regular time periods (i.e. the interval between collecting data is exactly the same - \\(t_2 - t_1 = t_1 - t_0\\) )","title":"What is a time series?"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#forms-of-time-series","text":"Univariate Time series Time series consisting of single observations over regular time intervals - for example, monthly returns data of a stock. Aim is to use past values of series data to predict future values - e.g. stocks, GDP, sales data e.g. forecasting inflation, unemployment rates, exchange rates, product demands, interest rates Multivariate Time series","title":"Forms of time series"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#emerging-patterns","text":"Depending on the frequency of data collection, we have different resolutions in our data - this allows for different patterns to emerge from the same situation (with differently collected data frequencies). Some example emerging patterns which may be observed: Trend data Upward or downward sloping long term direction persisting Seasonal data E.g. sales data Related to seasonal natural or human behaviour Cyclic data Pattern may last > 1 year Series follow up- and down- variations that are not seasonal E.g. budget patterns - might change across multiple years, resulting from recession/inflation - would expect to see a wave-like pattern Cycles may not necessarily be regular Random data Any data with no particular pattern - cannot be explained Irregularities Could be due to one-off issues occuring in data collection Stationarity A \"strictly stationary\" series is if the marginal distribution of \\(Y\\) at time \\(t[p(Y_t)]\\) is the same as at any other point in time. Therefore \\(p(Y_t) = p(Y_{t+k})\\) and \\(p(Y_t, Y_{t+k})\\) does not depend on \\(t\\) , where \\(t\\ge1\\) and \\(k\\) is any integer. This implies that mean, variance of covariant of series \\(Y_t\\) are time invariant A series is \"weakly stationary\" or \"covariance stationary\" if the following conditions are met: \\(E(Y_1) = E(Y_2) = E(Y_3) = ... = E(Y_t) = \\mu(constant)\\) \\(Var(Y_1) = Var(Y_2) = Var(Y_3) = ... = Var(Y_t) = \\gamma_0 (constant)\\) \\(Cov(Y_1, Y_{1+k}) = Cov(Y_2, Y_{2+k}) = Cov(Y_3, Y_{3+k}) = \\gamma_k\\) depending only on lag \\(k\\) . Stationarity assumption","title":"Emerging patterns"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#estimation-and-forecasting-methods","text":"The Box-Jenkins (B-J) methodology is used to estimate and forecast univariate time-series models. This includes the steps: Identification Autocorrelation function (ACF) Autocorrelation refers to how observations in a time series are related to each other, and is measured by a correlation between the current observation \\(Y_t\\) and the observation \\(p\\) periods from the current one \\(Y_{t-p}\\) . \\(\\rho_k = Corr(Y_t, Y_{t-p}) = \\frac{Cov(Y_t, Y_{t-p})}{\\sqrt{var(Y_t)}\\sqrt{var(Y_{t-p})}} = \\frac{\\gamma_p}{\\gamma_0}\\) Partial autocorrelation function (PACF) Partial autocorrelations are used to measure the degree of association between \\(Y_t\\) and \\(Y_{t-p}\\) when the effects at other time lags \\(1, 2, 3, ..., (p-1)\\) are removed - essentially like the ACF but we remove a few of the intermediate values. Inference from ACF and PACF Theoretical ACF and PACFs are available for various values of the lags of autoregressive and moving average components - e.g. \\(p\\) and \\(q\\) . A comparison of the correlograms (plot of sample ACFs vs. lags) of the time series data with theoretical ACFs and PACFs leads to the selection of the appropriate ARIMA \\((p, q)\\) model. Estimation Estimation methods usually determined by software Yule-Walker procedure Method of moments Maximum likelihood method Diagnostic checking Lowest value of AIC/BIC/SBIC - choose model with the lowest value of the criterion Plot the residual ACF - expect random residuals This method can only be applied to stationary series/variables. If the model is not stationary, you must differentiate and make the dataset stationary.","title":"Estimation and forecasting methods"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#time-series-processes-and-models","text":"White noise A time series is 'white noise' if it is purely random in nature. Let \\(\\epsilon_t\\) denote such a series. Then it has a zero mean \\(E(\\epsilon_t) = 0\\) , a constant variance \\(V(\\epsilon_t) = \\sigma^2\\) , and is an uncorrelated random variable \\(E(\\epsilon_t \\epsilon_s) = 0\\) . The scatter plot of such a plot will indicate no pattern - forecasting future values of such a series is not possible. i.e. STOP DOING TIME SERIES FORECASTING - it will be pointless The best forecast available for white noise is its average AutoRegressive (AR) models AutoRegressive (AR) models involve forecasting performed only on its own past values. That is, for a prediction \\(Y_t\\) , the forecast function is given as \\(Y_t = f(Y_{t-1}, Y_{t-2}, Y_{t-3}, ..., \\epsilon_t)\\) The question in these models is when do we stop taking past values (i.e. how many values of past \\(Y\\) should we take?) The general form is given by: \\(Y_t = \\beta_0 + \\beta_1Y_{t-1}+\\beta_2Y_{t-2}+\\beta_3Y_{t-3} + ... + \\beta_pY_{t-p}+\\epsilon_t\\) Moving Average (MA) model Moving average (MA) models involve forecasting by error terms - Consider forecasting each time-series point using its previous point: \\(Y_t = Y_{t-1} + \\beta_0 + \\epsilon_1\\) \\(Y_{t-1} = Y_{t-2} + \\beta_1 + \\epsilon_2\\) \\(Y_{t-2} = Y_{t-3} + \\beta_2 + \\epsilon_3\\) We would expect that the error terms \\(\\epsilon\\) are effectively white noise processes and have a mean of \\(0\\) and variance \\(\\sigma^2\\) (a constant). In the moving average (MA) model, we form a function on the error terms: \\(Y_t = \\beta_0 + \\epsilon_t + \\Phi_1\\epsilon_{t-1}+\\Phi_2\\epsilon_{t-2}+\\Phi_3\\epsilon_{t-3}+...+\\Phi_q\\epsilon_{t-q}\\) AutoRegressive Moving Average (ARMA) model People believe this model is more accurate than simple AutoRegressive or Moving Average models individually. The ARMA model depends on \\(p\\) , its own past values and \\(q\\) , the past values of white noise disturbances. The general formula takes the form: \\(Y_t = \\beta_0 + \\beta_1Y_{t-1}+\\beta_2Y_{t-2}+\\beta_3Y_{t-3}+...+\\beta_pY_{t-p}+\\epsilon_t+\\Phi_1\\epsilon_{t-1}+\\Phi_2\\epsilon_{t-2}+\\Phi_3\\epsilon_{t-3}+...+\\Phi_q\\epsilon_{t-q}\\) AutoRegressive Integrating Moving Average (ARIMA) model ARIMA models are applied to models with non-stationary series. A series which is stationary after being differentiated once is to be integrated of order 1, denoted \\(I(1)\\) . In its general form, a series which is stationary after being differentiated \\(d\\) times is denoted \\(I(d)\\) . A stationary series without differentiating is denoted \\(I(0)\\) . ARCH Garch ECM Panel data model","title":"Time series processes and models"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Introduction%20to%20Time%20Series%20Analysis/#references","text":"Youtube - Analytics University - https://www.youtube.com/watch?v=Aw77aMLj9uM","title":"References"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/Moving%20Average%20Models/","text":"","title":"Moving Average Models"},{"location":"Biostatistics/Advanced%20methods/Forecasting%20methods/Time%20Series%20Analysis/References%20for%20TSA/","text":"Wikipedia article - https://en.wikipedia.org/wiki/Time_series Unwatched - https://www.youtube.com/watch?v=aeW-XzTeIjg&ab_channel=ResearchByDesign - https://www.youtube.com/watch?v=HIWXdHlDSFs&ab_channel=AdhirHurjunlal - https://www.youtube.com/watch?v=Prpu_U5tKkE&ab_channel=JordanKern - https://www.youtube.com/watch?v=uBeM1FUk4Ps&ab_channel=MITOpenCourseWare - https://www.youtube.com/watch?v=ZuydOEws92s&ab_channel=HadiFanaee - https://www.youtube.com/watch?v=VYpAodcdFfA&ab_channel=InfoQ Reads - https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4.htm - https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775 - https://www.abs.gov.au/websitedbs/d3310114.nsf/home/time+series+analysis:+the+basics - https://otexts.com/fpp3/intro.html","title":"References for TSA"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/","text":"Machine Learning methods Machine learning methods are prevalent in data science, however their role in predictive risk scores are a bit less clear. The greatest benefit of the Machine Learning approach is the capacity to work with massive datasets with extremely large variable spaces - you find this kind of data is IoT (Internet of Things) datasets, hospital EMR systems, and web scraping systems (i.e. data mining). The general area ML methods are used is in biomedical informatics and digital health. These fields work more to do with building recommender systems (i.e. predictive models of a diagnostic or prognostic nature) using very large datasets (think 'Big Data'). In order to develop an appropriate ML model, you will still need to undertake the relevant steps, including training models , internal and external validation and using appropriate evaluation metrics including discrimination and calibration . A few relevant topics here include: Big Data linear regression K Nearest Neighbours Generalised Additive Models Linear Discriminant Analysis Quadratic Discriminant Analysis Decision Trees Support Vector Machines Neural Networks","title":"Machine Learning methods"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/#machine-learning-methods","text":"Machine learning methods are prevalent in data science, however their role in predictive risk scores are a bit less clear. The greatest benefit of the Machine Learning approach is the capacity to work with massive datasets with extremely large variable spaces - you find this kind of data is IoT (Internet of Things) datasets, hospital EMR systems, and web scraping systems (i.e. data mining). The general area ML methods are used is in biomedical informatics and digital health. These fields work more to do with building recommender systems (i.e. predictive models of a diagnostic or prognostic nature) using very large datasets (think 'Big Data'). In order to develop an appropriate ML model, you will still need to undertake the relevant steps, including training models , internal and external validation and using appropriate evaluation metrics including discrimination and calibration . A few relevant topics here include: Big Data linear regression K Nearest Neighbours Generalised Additive Models Linear Discriminant Analysis Quadratic Discriminant Analysis Decision Trees Support Vector Machines Neural Networks","title":"Machine Learning methods"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Big%20Data/","text":"","title":"Big Data"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Decision%20Trees/","text":"","title":"Decision Trees"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Generalised%20Additive%20Models/","text":"","title":"Generalised Additive Models"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/K%20Nearest%20Neighbours/","text":"","title":"K Nearest Neighbours"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Linear%20Discriminant%20Analysis/","text":"","title":"Linear Discriminant Analysis"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Neural%20Networks/","text":"","title":"Neural Networks"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Principal%20Components%20Analysis/","text":"","title":"Principal Components Analysis"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Quadratic%20Discriminant%20Analysis/","text":"","title":"Quadratic Discriminant Analysis"},{"location":"Biostatistics/Advanced%20methods/Machine%20Learning/Support%20Vector%20Machines/","text":"","title":"Support Vector Machines"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/","text":"Cox Proportional Hazards model Background The Proportional hazards regression model is given as \\( \\(h_i(t) = h_0(t)\\times e^{\\beta_1x_{i1} + ... + \\beta_px_{ip}}\\) \\) In this mode: \\(h_0(t)\\) is the baseline hazard function Taking the log of this model we get a log linear model The hazard ratio is defined as follows \\( \\(HR(t) = \\frac{h_2(t)}{h_1(t)}\\) \\) Uses of the Cox Proportional Hazards survival model Benefits of the Cox Proportional Hazards survival model: Allows for fluctuating hazards functions Can estimate hazard ratios Disadvantages of the Cox Proportional Hazards survival model Cannot estimate the survival function Statistical assumptions of the Cox PH model This is a semi-parametric survival model. The Cox proportional hazards model assumes a constant hazard ratio. In the CoxPH model, the estimated coefficients have an approximately normal distribution when there are adequate numbers of events Hypothesis testing in the CoxPH model Two hypothesis testing are available: Wald test Likelihood ratio test This gives more accurate p-values when the dataset has fewer events These two tests are asymptotically the same Confidence intervals Confidence interval for \\(\\hat{\\beta}\\) : \\((1-\\alpha)\\times 100\\% CI = \\hat{\\beta} \\pm Z_{1-\\alpha/2}\\times \\hat{se}(\\hat{\\beta})\\) Confidence interval for the HR:","title":"Cox Proportional Hazards model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/#cox-proportional-hazards-model","text":"","title":"Cox Proportional Hazards model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/#background","text":"The Proportional hazards regression model is given as \\( \\(h_i(t) = h_0(t)\\times e^{\\beta_1x_{i1} + ... + \\beta_px_{ip}}\\) \\) In this mode: \\(h_0(t)\\) is the baseline hazard function Taking the log of this model we get a log linear model The hazard ratio is defined as follows \\( \\(HR(t) = \\frac{h_2(t)}{h_1(t)}\\) \\)","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/#uses-of-the-cox-proportional-hazards-survival-model","text":"Benefits of the Cox Proportional Hazards survival model: Allows for fluctuating hazards functions Can estimate hazard ratios Disadvantages of the Cox Proportional Hazards survival model Cannot estimate the survival function","title":"Uses of the Cox Proportional Hazards survival model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/#statistical-assumptions-of-the-cox-ph-model","text":"This is a semi-parametric survival model. The Cox proportional hazards model assumes a constant hazard ratio. In the CoxPH model, the estimated coefficients have an approximately normal distribution when there are adequate numbers of events","title":"Statistical assumptions of the Cox PH model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/#hypothesis-testing-in-the-coxph-model","text":"Two hypothesis testing are available: Wald test Likelihood ratio test This gives more accurate p-values when the dataset has fewer events These two tests are asymptotically the same","title":"Hypothesis testing in the CoxPH model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Cox%20Proportional%20Hazards%20model/#confidence-intervals","text":"Confidence interval for \\(\\hat{\\beta}\\) : \\((1-\\alpha)\\times 100\\% CI = \\hat{\\beta} \\pm Z_{1-\\alpha/2}\\times \\hat{se}(\\hat{\\beta})\\) Confidence interval for the HR:","title":"Confidence intervals"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Exponential%20and%20Weibull%20survival%20models/","text":"Exponential and Weibull survival models Background The exponential survival model can be given as: \\[S(t) = e^{-h(t) \\times t}\\] The exponential survival model and the Weibull survival model have similar statistical bases, however, the Weibull model allows the hazard to increase or decrease proportionally with time Uses of the Exponential survival model Benefits of the Exponential survival model: Can estimate survival function \\(S(t)\\) AND Hazard ratios Disadvantages of the Exponential survival model Not always realistic Assumes a constant hazard - in order to fit a negative exponential curve Consider as we age, our risk of dying increases - the exponential model clearly wouldn't account for ageing However the weibull model can partially account for this but allowing hazard to increase or decrease proportionally with time Statistical assumptions This is a parametric survival model This is a negative exponential model See the Poisson Process","title":"Exponential and Weibull survival models"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Exponential%20and%20Weibull%20survival%20models/#exponential-and-weibull-survival-models","text":"","title":"Exponential and Weibull survival models"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Exponential%20and%20Weibull%20survival%20models/#background","text":"The exponential survival model can be given as: \\[S(t) = e^{-h(t) \\times t}\\] The exponential survival model and the Weibull survival model have similar statistical bases, however, the Weibull model allows the hazard to increase or decrease proportionally with time","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Exponential%20and%20Weibull%20survival%20models/#uses-of-the-exponential-survival-model","text":"Benefits of the Exponential survival model: Can estimate survival function \\(S(t)\\) AND Hazard ratios Disadvantages of the Exponential survival model Not always realistic Assumes a constant hazard - in order to fit a negative exponential curve Consider as we age, our risk of dying increases - the exponential model clearly wouldn't account for ageing However the weibull model can partially account for this but allowing hazard to increase or decrease proportionally with time","title":"Uses of the Exponential survival model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Exponential%20and%20Weibull%20survival%20models/#statistical-assumptions","text":"This is a parametric survival model This is a negative exponential model See the Poisson Process","title":"Statistical assumptions"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Kaplan-Meier%20survival%20model/","text":"Kaplan-Meier survival curve Background Used to represent survival data in a non-parametric manner. In order to build the Kaplan-meier survival curve, you need to build a Life Table . This can be done by hand (shown in the previous link) but statical packages can do it without much thought. Uses of the K-M survival model Benefits of the K-M survival model: Simple to interpret model Can estimate survival \\(S(t)\\) beyond a certain time Disadvantages of the K-M survival model No functional form and no mathematical representation of the K-M survival model (As it is non-parametric) Cannot estimate a hazard ratio - as this is not a smooth curve, at any point in time the HR is likely 0 Can only include a few, categorical X values Cannot handle continuous predictors - can only handle categorical ones Statistics of this model This is a non-parametric model Explanation of the curve At any time (t), read the y-axis value This is the probability of surviving past time t At \\(S(t) = 0.5\\) , we have the median survival time Similarly you can figure out the IQR","title":"Kaplan-Meier survival curve"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Kaplan-Meier%20survival%20model/#kaplan-meier-survival-curve","text":"","title":"Kaplan-Meier survival curve"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Kaplan-Meier%20survival%20model/#background","text":"Used to represent survival data in a non-parametric manner. In order to build the Kaplan-meier survival curve, you need to build a Life Table . This can be done by hand (shown in the previous link) but statical packages can do it without much thought.","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Kaplan-Meier%20survival%20model/#uses-of-the-k-m-survival-model","text":"Benefits of the K-M survival model: Simple to interpret model Can estimate survival \\(S(t)\\) beyond a certain time Disadvantages of the K-M survival model No functional form and no mathematical representation of the K-M survival model (As it is non-parametric) Cannot estimate a hazard ratio - as this is not a smooth curve, at any point in time the HR is likely 0 Can only include a few, categorical X values Cannot handle continuous predictors - can only handle categorical ones","title":"Uses of the K-M survival model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Kaplan-Meier%20survival%20model/#statistics-of-this-model","text":"This is a non-parametric model","title":"Statistics of this model"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Kaplan-Meier%20survival%20model/#explanation-of-the-curve","text":"At any time (t), read the y-axis value This is the probability of surviving past time t At \\(S(t) = 0.5\\) , we have the median survival time Similarly you can figure out the IQR","title":"Explanation of the curve"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Life%20Table/","text":"Life Table (Survival Table) Background The life stable is a tool used to help calculate survival rates - it is not shown or published in research papers. We use it to calculate the probability of surviving to a certain point in time. Survival curve When plotting the survival table, you get the Survival Curve . When the specific time intervals in which the patients reach the endpoint are known, we have the Kaplan-Meier survival model . Example of how to build a life table by hand Consider the following situation where we look at time-to-death following diagnosis. The initiall data looks as follows: |Time| Death?|Explanation| |----|----|----| |2|1|One person died at t=2| |3|0|One person left the study at t=3| |6|1|one person died at t=6| |6|1|another person died at t=6| |7|1|one person died at t=7| |10|0|one person left the study at t=10| |15|1| | |16|1| | |27|1| | |30|1| | |32|1| | Lets use this to build a survival table: Time Number at Risk Number died Hazard 1-Hazard Survival \\(S(t)\\) 0 12 0 0/12 12/12 1 = 100% 2 12 1 1/12 1-1/12=11/12 11/12 = 0.917 6 12 - 1(death) - 1(loss to censoring) = 10 2 2/10 0.917 (8/10) 0.734 7 8 1 1/8 7/8 0.734 (7/8) = 0.642 15 6 2 2/6 4/6 0.642(4/6) = 0.428 16 4 1 1/4 3/4 0.428 (1/4) = 0.321 27 3 1 1/3 2/3 0.321 (1/3) = 0.214 30 2 1 1/2 1/2 0.214 (1/2) = 0.107 32 1 1 1/1 0/1 0.107 (0/1) = 0 Turning this into a K-M curve:","title":"Life Table (Survival Table)"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Life%20Table/#life-table-survival-table","text":"","title":"Life Table (Survival Table)"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Life%20Table/#background","text":"The life stable is a tool used to help calculate survival rates - it is not shown or published in research papers. We use it to calculate the probability of surviving to a certain point in time.","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Life%20Table/#survival-curve","text":"When plotting the survival table, you get the Survival Curve . When the specific time intervals in which the patients reach the endpoint are known, we have the Kaplan-Meier survival model .","title":"Survival curve"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Life%20Table/#example-of-how-to-build-a-life-table-by-hand","text":"Consider the following situation where we look at time-to-death following diagnosis. The initiall data looks as follows: |Time| Death?|Explanation| |----|----|----| |2|1|One person died at t=2| |3|0|One person left the study at t=3| |6|1|one person died at t=6| |6|1|another person died at t=6| |7|1|one person died at t=7| |10|0|one person left the study at t=10| |15|1| | |16|1| | |27|1| | |30|1| | |32|1| | Lets use this to build a survival table: Time Number at Risk Number died Hazard 1-Hazard Survival \\(S(t)\\) 0 12 0 0/12 12/12 1 = 100% 2 12 1 1/12 1-1/12=11/12 11/12 = 0.917 6 12 - 1(death) - 1(loss to censoring) = 10 2 2/10 0.917 (8/10) 0.734 7 8 1 1/8 7/8 0.734 (7/8) = 0.642 15 6 2 2/6 4/6 0.642(4/6) = 0.428 16 4 1 1/4 3/4 0.428 (1/4) = 0.321 27 3 1 1/3 2/3 0.321 (1/3) = 0.214 30 2 1 1/2 1/2 0.214 (1/2) = 0.107 32 1 1 1/1 0/1 0.107 (0/1) = 0 Turning this into a K-M curve:","title":"Example of how to build a life table by hand"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Logrank%20test/","text":"Logrank test Background Used to compare survival curves Underlying statistical assumptions The logrank test is a non-parametric test and does not make assumptions regarding the shape of the survival curve","title":"Logrank test"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Logrank%20test/#logrank-test","text":"","title":"Logrank test"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Logrank%20test/#background","text":"Used to compare survival curves","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Logrank%20test/#underlying-statistical-assumptions","text":"The logrank test is a non-parametric test and does not make assumptions regarding the shape of the survival curve","title":"Underlying statistical assumptions"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Poisson%20Process/","text":"Poisson process Background The poisson process is used when we look at events that occur independently over time Mathematically: $$ Rate = \\lambda = \\frac{y}{t}$$ That is, y (event occurence) per unit time (t) This gives rise to two distributions: Poisson distribution - Let \\(y\\) = number of of occurences in time \\(t\\) y","title":"Poisson process"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Poisson%20Process/#poisson-process","text":"","title":"Poisson process"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Poisson%20Process/#background","text":"The poisson process is used when we look at events that occur independently over time Mathematically: $$ Rate = \\lambda = \\frac{y}{t}$$ That is, y (event occurence) per unit time (t) This gives rise to two distributions: Poisson distribution - Let \\(y\\) = number of of occurences in time \\(t\\) y","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/","text":"Survival Analysis Survival data Survival data refers to data representing time-to-event. These events can include (but aren't limited to): Death Development of metastasis/local tumour recurrence Hospital readmission Breast feeding cessation The time in which the event occurs is the 'endpoint'. Censorship Data is censored when we do not whether or not the endpoint is achieved. There are two main types of censorship: Right-censored - when we know the endpoint occurs after the last recorded observation e.g. in a clinical trial looking at metastatic recurrence, patient X has had their last measurement at 1 year and their last measurement was they did not have recurrence. They were then lost to follow up. We know that patient X MAY have had a recurrence AFTER 1 year, and therefore the end-point would be achieved AFTER the last observation. This is right-censored. Left-censored - when the endpoint has occured before enrolment This is rarely encountered Patients are censored if: - They are lost to follow-up - They withdraw from the study Truncation Life Table After accumulating all the survival time points of the participants (And when they are censored), we can generate and calculate a Life Table Survival time and statistics The survival function is given by: \\( \\(S(t) = P(T > t)\\) \\) This function consists of: \\(S(t)\\) - the survival time \\(P(T>t)\\) - the probability of survival time \\(T\\) beyond the defined time \\(t\\) The hazard function is given by \\( \\(h(t) = P(T < t + \\delta | T > t)\\) \\) This means Given that you are alive ( \\(T > t\\) ), what is the probability of you dying ( \\(T < t\\) ) in the next few seconds ( \\(+\\delta\\) ) Another way of thinking of the hazard function - it is the rate of decrease of the exponential survival curve The Hazard Ratio is given by $$ HR = \\frac{h_1(t)}{h_0(t)}$$ That is: The ratio of hazard at x = 1 vs the hazard at x=0 E.g. if the HR = 2 That is exposure (x=1) has a 2x higher hazard compared to non exposure (x = 0) Models in survival analysis There are three main models used in survival analysis: Kaplan-Meier models Exponential and Weibull survival models Cox Proportional Hazards model","title":"Survival Analysis"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#survival-analysis","text":"","title":"Survival Analysis"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#survival-data","text":"Survival data refers to data representing time-to-event. These events can include (but aren't limited to): Death Development of metastasis/local tumour recurrence Hospital readmission Breast feeding cessation The time in which the event occurs is the 'endpoint'.","title":"Survival data"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#censorship","text":"Data is censored when we do not whether or not the endpoint is achieved. There are two main types of censorship: Right-censored - when we know the endpoint occurs after the last recorded observation e.g. in a clinical trial looking at metastatic recurrence, patient X has had their last measurement at 1 year and their last measurement was they did not have recurrence. They were then lost to follow up. We know that patient X MAY have had a recurrence AFTER 1 year, and therefore the end-point would be achieved AFTER the last observation. This is right-censored. Left-censored - when the endpoint has occured before enrolment This is rarely encountered Patients are censored if: - They are lost to follow-up - They withdraw from the study","title":"Censorship"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#truncation","text":"","title":"Truncation"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#life-table","text":"After accumulating all the survival time points of the participants (And when they are censored), we can generate and calculate a Life Table","title":"Life Table"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#survival-time-and-statistics","text":"The survival function is given by: \\( \\(S(t) = P(T > t)\\) \\) This function consists of: \\(S(t)\\) - the survival time \\(P(T>t)\\) - the probability of survival time \\(T\\) beyond the defined time \\(t\\) The hazard function is given by \\( \\(h(t) = P(T < t + \\delta | T > t)\\) \\) This means Given that you are alive ( \\(T > t\\) ), what is the probability of you dying ( \\(T < t\\) ) in the next few seconds ( \\(+\\delta\\) ) Another way of thinking of the hazard function - it is the rate of decrease of the exponential survival curve The Hazard Ratio is given by $$ HR = \\frac{h_1(t)}{h_0(t)}$$ That is: The ratio of hazard at x = 1 vs the hazard at x=0 E.g. if the HR = 2 That is exposure (x=1) has a 2x higher hazard compared to non exposure (x = 0)","title":"Survival time and statistics"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Analysis/#models-in-survival-analysis","text":"There are three main models used in survival analysis: Kaplan-Meier models Exponential and Weibull survival models Cox Proportional Hazards model","title":"Models in survival analysis"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Curve/","text":"Survival Curve Background Comparing survival curves Survival curves can be compared with the following significance tests Logrank test - the most well-known test arfe test","title":"Survival Curve"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Curve/#survival-curve","text":"","title":"Survival Curve"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Curve/#background","text":"","title":"Background"},{"location":"Biostatistics/Biostatistical%20modelling/Survival%20analysis/Survival%20Curve/#comparing-survival-curves","text":"Survival curves can be compared with the following significance tests Logrank test - the most well-known test arfe test","title":"Comparing survival curves"},{"location":"Biostatistics/Data%20Visualisation/Frequency%20tables/","text":"Frequency tables Background and use Frequency tables are useful in looking at categorical data. Examples R-code table(data$column)","title":"Frequency tables"},{"location":"Biostatistics/Data%20Visualisation/Frequency%20tables/#frequency-tables","text":"","title":"Frequency tables"},{"location":"Biostatistics/Data%20Visualisation/Frequency%20tables/#background-and-use","text":"Frequency tables are useful in looking at categorical data.","title":"Background and use"},{"location":"Biostatistics/Data%20Visualisation/Frequency%20tables/#examples","text":"","title":"Examples"},{"location":"Biostatistics/Data%20Visualisation/Frequency%20tables/#r-code","text":"table(data$column)","title":"R-code"},{"location":"Biostatistics/Data%20Visualisation/Plots/","text":"Plots Important in visualisation of data Histograms hist(data$column, xlab=\"x_label\", ylab = \"y_label\", main=\"\") Boxplots boxplot(data$column) Barcharts barplot(data$column)","title":"Plots"},{"location":"Biostatistics/Data%20Visualisation/Plots/#plots","text":"Important in visualisation of data","title":"Plots"},{"location":"Biostatistics/Data%20Visualisation/Plots/#histograms","text":"hist(data$column, xlab=\"x_label\", ylab = \"y_label\", main=\"\")","title":"Histograms"},{"location":"Biostatistics/Data%20Visualisation/Plots/#boxplots","text":"boxplot(data$column)","title":"Boxplots"},{"location":"Biostatistics/Data%20Visualisation/Plots/#barcharts","text":"barplot(data$column)","title":"Barcharts"},{"location":"Biostatistics/Data%20Visualisation/References%20for%20Data%20Visualisation/","text":"https://clauswilke.com/dataviz/aesthetic-mapping.html https://socviz.co/","title":"References for Data Visualisation"},{"location":"Biostatistics/Medical%20Statistics/Binomial%20Distribution/","text":"","title":"Binomial Distribution"},{"location":"Biostatistics/Medical%20Statistics/Central%20Limit%20Theorem/","text":"Central Limit Theorem Definition The central limit theoreom (CLT) states that if random samples are taken from ANY distribution, then the distribution of the SAMPLES' means \\(\\bar{x}\\) will be approximately Normal This theorem gets better as n , the number of points sampled, gets larger. Standard error of a sample mean","title":"Central Limit Theorem"},{"location":"Biostatistics/Medical%20Statistics/Central%20Limit%20Theorem/#central-limit-theorem","text":"","title":"Central Limit Theorem"},{"location":"Biostatistics/Medical%20Statistics/Central%20Limit%20Theorem/#definition","text":"The central limit theoreom (CLT) states that if random samples are taken from ANY distribution, then the distribution of the SAMPLES' means \\(\\bar{x}\\) will be approximately Normal This theorem gets better as n , the number of points sampled, gets larger.","title":"Definition"},{"location":"Biostatistics/Medical%20Statistics/Central%20Limit%20Theorem/#standard-error-of-a-sample-mean","text":"","title":"Standard error of a sample mean"},{"location":"Biostatistics/Medical%20Statistics/Confidence%20Intervals/","text":"Confidence Intervals Definition and purpose Known Standard Deviation Unknown Standard Deviation","title":"Confidence Intervals"},{"location":"Biostatistics/Medical%20Statistics/Confidence%20Intervals/#confidence-intervals","text":"","title":"Confidence Intervals"},{"location":"Biostatistics/Medical%20Statistics/Confidence%20Intervals/#definition-and-purpose","text":"","title":"Definition and purpose"},{"location":"Biostatistics/Medical%20Statistics/Confidence%20Intervals/#known-standard-deviation","text":"","title":"Known Standard Deviation"},{"location":"Biostatistics/Medical%20Statistics/Confidence%20Intervals/#unknown-standard-deviation","text":"","title":"Unknown Standard Deviation"},{"location":"Biostatistics/Medical%20Statistics/Data%20types/","text":"Data types","title":"Data types"},{"location":"Biostatistics/Medical%20Statistics/Data%20types/#data-types","text":"","title":"Data types"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/","text":"Descriptive statistics Terminology Types of Variables Term Definition Variable Item of data that can be observed or measured on individuals Quantitative variable A variable that can be counted or measured Discrete variable A quantitative variable whose possible values are integers (whole numbers) e.g. numbero f children, number of vitis to GP in a year Continuous variable A quantitative variable that has an uninterrupted range of values, e.g. blood presure, weight Qualitative (categorical) variable A variable that is not characterised by a numerical quantity, e.g. sex, occupation, type of housing, type of diet, category of disease Ordinal variable Qualitative variable with several ORDERED categories (e.g. very poor diet, poor, fair, good, very good) Nominal variable Qualitative variable of UNORDERED categories Dichotomous variable Qualitative variable of binary classification (yes/no) Summary data Term Definition Frequency Number of individuals with certain characteristic, or withi na certain range of a variable Relative frequency A frequency expressed as a proportion or precentage of total frequency Cumulative frequency At any value of a variable, the sum of the frequencies that are less than or equal to that value Cumulative relative frequency At any value of a variable, the sum of the frequencies that are less than or equal to that value, expressed as a proportion or percentage of the total frequency Sampling Greek letters used in statistics Summary Statistics Notation Measures of Location Mean Median Mode Selecting a representative value of location Measures of Variability Range Variance and Standard deviation Coefficient of variation Quartiles, Deciles and Centiles Tables One-way table of frequencies Maternal age (years) Frequency Relative frequency (%) Cumulative frequency Cumulative relative frequency (%) <20 163 0.3 163 0.3 20-24 3,214 6.2 3,377 6.5 25-29 10,238 19.7 13,615 26.2 30-34 20,217 38.8 33,832 65.0 30-39 14,474 27.8 48,306 92.8 >=40 3,756 7.2 52,062 100.0 Note about frequency tables: Cumulative relative frequency is not necessary to report unless categories show clear ordering (e.g. if your grouping is based on parity) Percentages should be presented as whole values when \\(n < 100\\) Do not include vertical lines in your table Columns should be labelled appropriately in whole words Two-way table of frequencies Figures Bar Charts Simple bar charts Plot quantitative discrete or qualitative variables Multiple and composite bar charts Multiple side-by-side bars or stacked bars to show relationship between variables Histograms Bars demonstrating frequency distributions of continuous variables Stem-and-leaf plots Similar to histograms, however provides more insight into detail numerically Stems are the digits to the left of the vertical line Leaves are the digits to the right of the vertical line Monospace fonts such as Courier should be used to give a macroscopic histogram on inspection Cumulative relative frequency plot Line plot where cumulative relative frequency is plotted against the independent variable/variable of interest. Boxplot Rules of figure and table presentation Tables and figures should be self-explanatory and easy to read, with title, (pg15) Rules for Rounding of results Numberse should be reported with an appropriate degree of precision. (pg16)","title":"Descriptive statistics"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#descriptive-statistics","text":"","title":"Descriptive statistics"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#terminology","text":"","title":"Terminology"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#types-of-variables","text":"Term Definition Variable Item of data that can be observed or measured on individuals Quantitative variable A variable that can be counted or measured Discrete variable A quantitative variable whose possible values are integers (whole numbers) e.g. numbero f children, number of vitis to GP in a year Continuous variable A quantitative variable that has an uninterrupted range of values, e.g. blood presure, weight Qualitative (categorical) variable A variable that is not characterised by a numerical quantity, e.g. sex, occupation, type of housing, type of diet, category of disease Ordinal variable Qualitative variable with several ORDERED categories (e.g. very poor diet, poor, fair, good, very good) Nominal variable Qualitative variable of UNORDERED categories Dichotomous variable Qualitative variable of binary classification (yes/no)","title":"Types of Variables"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#summary-data","text":"Term Definition Frequency Number of individuals with certain characteristic, or withi na certain range of a variable Relative frequency A frequency expressed as a proportion or precentage of total frequency Cumulative frequency At any value of a variable, the sum of the frequencies that are less than or equal to that value Cumulative relative frequency At any value of a variable, the sum of the frequencies that are less than or equal to that value, expressed as a proportion or percentage of the total frequency","title":"Summary data"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#sampling","text":"","title":"Sampling"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#greek-letters-used-in-statistics","text":"","title":"Greek letters used in statistics"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#summary-statistics","text":"","title":"Summary Statistics"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#notation","text":"","title":"Notation"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#measures-of-location","text":"","title":"Measures of Location"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#mean","text":"","title":"Mean"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#median","text":"","title":"Median"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#mode","text":"","title":"Mode"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#selecting-a-representative-value-of-location","text":"","title":"Selecting a representative value of location"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#measures-of-variability","text":"","title":"Measures of Variability"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#range","text":"","title":"Range"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#variance-and-standard-deviation","text":"","title":"Variance and Standard deviation"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#coefficient-of-variation","text":"","title":"Coefficient of variation"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#quartiles-deciles-and-centiles","text":"","title":"Quartiles, Deciles and Centiles"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#tables","text":"","title":"Tables"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#one-way-table-of-frequencies","text":"Maternal age (years) Frequency Relative frequency (%) Cumulative frequency Cumulative relative frequency (%) <20 163 0.3 163 0.3 20-24 3,214 6.2 3,377 6.5 25-29 10,238 19.7 13,615 26.2 30-34 20,217 38.8 33,832 65.0 30-39 14,474 27.8 48,306 92.8 >=40 3,756 7.2 52,062 100.0 Note about frequency tables: Cumulative relative frequency is not necessary to report unless categories show clear ordering (e.g. if your grouping is based on parity) Percentages should be presented as whole values when \\(n < 100\\) Do not include vertical lines in your table Columns should be labelled appropriately in whole words","title":"One-way table of frequencies"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#two-way-table-of-frequencies","text":"","title":"Two-way table of frequencies"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#figures","text":"","title":"Figures"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#bar-charts","text":"Simple bar charts Plot quantitative discrete or qualitative variables Multiple and composite bar charts Multiple side-by-side bars or stacked bars to show relationship between variables","title":"Bar Charts"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#histograms","text":"Bars demonstrating frequency distributions of continuous variables","title":"Histograms"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#stem-and-leaf-plots","text":"Similar to histograms, however provides more insight into detail numerically Stems are the digits to the left of the vertical line Leaves are the digits to the right of the vertical line Monospace fonts such as Courier should be used to give a macroscopic histogram on inspection","title":"Stem-and-leaf plots"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#cumulative-relative-frequency-plot","text":"Line plot where cumulative relative frequency is plotted against the independent variable/variable of interest.","title":"Cumulative relative frequency plot"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#boxplot","text":"","title":"Boxplot"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#rules-of-figure-and-table-presentation","text":"Tables and figures should be self-explanatory and easy to read, with title, (pg15)","title":"Rules of figure and table presentation"},{"location":"Biostatistics/Medical%20Statistics/Descriptive%20statistics/#rules-for-rounding-of-results","text":"Numberse should be reported with an appropriate degree of precision. (pg16)","title":"Rules for Rounding of results"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/","text":"Hypothesis testing Introduction to hypothesis testing P-values and confidence intervals see Confidence Intervals One sample t-test with continuous variable One sample t-test with continuous variable and known standard deviation One sample t-test with continuous variable and unknown standard deviation Paired t-test (Paired Means test) Two sample t-test (Twio Independent Means) Student's Two Sample t-test Significance Test for a Proportion McNemar's Test Chi-Squared Test","title":"Hypothesis testing"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#hypothesis-testing","text":"","title":"Hypothesis testing"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#introduction-to-hypothesis-testing","text":"","title":"Introduction to hypothesis testing"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#p-values-and-confidence-intervals","text":"see Confidence Intervals","title":"P-values and confidence intervals"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#one-sample-t-test-with-continuous-variable","text":"","title":"One sample t-test with continuous variable"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#one-sample-t-test-with-continuous-variable-and-known-standard-deviation","text":"","title":"One sample t-test with continuous variable and known standard deviation"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#one-sample-t-test-with-continuous-variable-and-unknown-standard-deviation","text":"","title":"One sample t-test with continuous variable and unknown standard deviation"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#paired-t-test-paired-means-test","text":"","title":"Paired t-test (Paired Means test)"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#two-sample-t-test-twio-independent-means","text":"","title":"Two sample t-test (Twio Independent Means)"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#students-two-sample-t-test","text":"","title":"Student's Two Sample t-test"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#significance-test-for-a-proportion","text":"","title":"Significance Test for a Proportion"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#mcnemars-test","text":"","title":"McNemar's Test"},{"location":"Biostatistics/Medical%20Statistics/Hypothesis%20testing/#chi-squared-test","text":"","title":"Chi-Squared Test"},{"location":"Biostatistics/Medical%20Statistics/Kendall%27s%20rank%20correlation%20coefficient/","text":"","title":"Kendall's rank correlation coefficient"},{"location":"Biostatistics/Medical%20Statistics/Mann-Whitney%20U%20test/","text":"Mann-Whitney U test","title":"Mann-Whitney U test"},{"location":"Biostatistics/Medical%20Statistics/Mann-Whitney%20U%20test/#mann-whitney-u-test","text":"","title":"Mann-Whitney U test"},{"location":"Biostatistics/Medical%20Statistics/Medical%20Statistics/","text":"Medical statistics This section in Medical Statistics aims to cover the content you will normally find in an Introduction to biostatistics course at university. The contents for such a course include: Descriptive statistics Normal Distribution Central Limit Theorem Confidence Intervals Hypothesis testing Binomial Distribution Small Sample Tests Non-Parametric Tests Sample Size and Power Simple Linear Regression Multivariable Models graph TB A[One or two samples?] --> |One|E; A --> |Two|B B[Paired or Independent?] --> |Paired|C((Go to page E2)) B --> |Independent|D((Go to page E3)) E[Is your variable Categorical or Continuous?] E --> |Categorical|F[Z-score] E -->|Continuous|G[Can you assume data are normally distributed?] G-->|Yes|H[Population Standard deviation known?] H --> |Yes|I[z-score] H --> |No|K[One sample t-test] G--> |No|J[Wilcoxon Signed Rank Test] References The content for this section of this website are derived from: The content I learnt from PUBH5018 - Introductory Biostatistics (University of Sydney) Martin Bland - An Introduction to Medical Statistics 3rd Ed","title":"Medical statistics"},{"location":"Biostatistics/Medical%20Statistics/Medical%20Statistics/#medical-statistics","text":"This section in Medical Statistics aims to cover the content you will normally find in an Introduction to biostatistics course at university. The contents for such a course include: Descriptive statistics Normal Distribution Central Limit Theorem Confidence Intervals Hypothesis testing Binomial Distribution Small Sample Tests Non-Parametric Tests Sample Size and Power Simple Linear Regression Multivariable Models graph TB A[One or two samples?] --> |One|E; A --> |Two|B B[Paired or Independent?] --> |Paired|C((Go to page E2)) B --> |Independent|D((Go to page E3)) E[Is your variable Categorical or Continuous?] E --> |Categorical|F[Z-score] E -->|Continuous|G[Can you assume data are normally distributed?] G-->|Yes|H[Population Standard deviation known?] H --> |Yes|I[z-score] H --> |No|K[One sample t-test] G--> |No|J[Wilcoxon Signed Rank Test]","title":"Medical statistics"},{"location":"Biostatistics/Medical%20Statistics/Medical%20Statistics/#references","text":"The content for this section of this website are derived from: The content I learnt from PUBH5018 - Introductory Biostatistics (University of Sydney) Martin Bland - An Introduction to Medical Statistics 3rd Ed","title":"References"},{"location":"Biostatistics/Medical%20Statistics/Multivariable%20Models/","text":"","title":"Multivariable Models"},{"location":"Biostatistics/Medical%20Statistics/Non-Parametric%20Tests/","text":"Non-Parametric test Background Parametric methods refer to methods which rely upon an estimation of the underlying distribution - for example, tests which assume a Normal Distribution in its variables are parametric. Non-parametric methods thus do not assume a family of distributions. Examples include 1. Sign test 2. Large sample Normal test 3. Mann-Whitney U test 4. Wilcoxon matched pairs test 5. Spearman's rank correlation coefficient 6. Kendall's rank correlation coefficient Continuity correction","title":"Non-Parametric test"},{"location":"Biostatistics/Medical%20Statistics/Non-Parametric%20Tests/#non-parametric-test","text":"","title":"Non-Parametric test"},{"location":"Biostatistics/Medical%20Statistics/Non-Parametric%20Tests/#background","text":"Parametric methods refer to methods which rely upon an estimation of the underlying distribution - for example, tests which assume a Normal Distribution in its variables are parametric. Non-parametric methods thus do not assume a family of distributions. Examples include 1. Sign test 2. Large sample Normal test 3. Mann-Whitney U test 4. Wilcoxon matched pairs test 5. Spearman's rank correlation coefficient 6. Kendall's rank correlation coefficient","title":"Background"},{"location":"Biostatistics/Medical%20Statistics/Non-Parametric%20Tests/#continuity-correction","text":"","title":"Continuity correction"},{"location":"Biostatistics/Medical%20Statistics/Normal%20Distribution/","text":"Normal (Gaussian) Distribution Background The normal distribution (otherwise known as the Gaussian distribution) is a specific distribution with two main features: It is symmetrical about its mean It is a bell-shaped curve which is peaked in its centre Most measurements taken from a continuous variable in real world practice come out to be normally distributed. This includes: Baby birthweights Maternal age at giving birth Average weight of the population As such the normal distribution is extremely important in medical statistics. The Normal distribution is also important because of Central Limit Theorem . Normal Distribution descriptors The Normal distribution is described by its mean \\(\\mu\\) and standard deviation \\(\\sigma\\) .","title":"Normal (Gaussian) Distribution"},{"location":"Biostatistics/Medical%20Statistics/Normal%20Distribution/#normal-gaussian-distribution","text":"","title":"Normal (Gaussian) Distribution"},{"location":"Biostatistics/Medical%20Statistics/Normal%20Distribution/#background","text":"The normal distribution (otherwise known as the Gaussian distribution) is a specific distribution with two main features: It is symmetrical about its mean It is a bell-shaped curve which is peaked in its centre Most measurements taken from a continuous variable in real world practice come out to be normally distributed. This includes: Baby birthweights Maternal age at giving birth Average weight of the population As such the normal distribution is extremely important in medical statistics. The Normal distribution is also important because of Central Limit Theorem .","title":"Background"},{"location":"Biostatistics/Medical%20Statistics/Normal%20Distribution/#normal-distribution-descriptors","text":"The Normal distribution is described by its mean \\(\\mu\\) and standard deviation \\(\\sigma\\) .","title":"Normal Distribution descriptors"},{"location":"Biostatistics/Medical%20Statistics/Probability/","text":"Probability Background Probability is the chance of an event occuring It can be measured from 0 (NEVER) to 1 (ALWAYS) Two views when considering probability LONG TERM frequency - i.e. over an extended period of time/occurences, what is the chance of something happening e.g. coin flip - if you flip a coin enough, half of those flips should end up on heads \\(P(head) = 0.5\\) SUBJECTIVE measure of our belief in the chances of an event occuring e.g. 'There is a 10% chance of an effective vaccine against TB by the year 2020' The event can ONLY occur once - there is no point thinking of long term frequency as the frequency = 1 These probabilities give us a perspective in long term decision making Probability distribution The probability of something occuring will fall under a distribution. The distribution itself must contain all possible outcomes . When you have categorical outcomes (E.g. the sex of a baby), the distributions may look like the following: However when you have continuous outcomes (e.g. the weight of your baby), you will get a probability distribution that more resembles a curve (depending on how large your interval widths are). As you make the interval widths infinitely small (i.e. to the point where you smooth out this curve), the probability set will form a 'probability density curve' - make no mistake, these represent the same thing, however the 'probability density curve' would moreso be an interpretation (i.e. model) of the data, rather than a representation of the data itself. Note the sum of all probabilities must equal to 1 in a probability distribution (i.e. the Area under the curve) One common probability distribution you will see is the Normal Distribution","title":"Probability"},{"location":"Biostatistics/Medical%20Statistics/Probability/#probability","text":"","title":"Probability"},{"location":"Biostatistics/Medical%20Statistics/Probability/#background","text":"Probability is the chance of an event occuring It can be measured from 0 (NEVER) to 1 (ALWAYS) Two views when considering probability LONG TERM frequency - i.e. over an extended period of time/occurences, what is the chance of something happening e.g. coin flip - if you flip a coin enough, half of those flips should end up on heads \\(P(head) = 0.5\\) SUBJECTIVE measure of our belief in the chances of an event occuring e.g. 'There is a 10% chance of an effective vaccine against TB by the year 2020' The event can ONLY occur once - there is no point thinking of long term frequency as the frequency = 1 These probabilities give us a perspective in long term decision making","title":"Background"},{"location":"Biostatistics/Medical%20Statistics/Probability/#probability-distribution","text":"The probability of something occuring will fall under a distribution. The distribution itself must contain all possible outcomes . When you have categorical outcomes (E.g. the sex of a baby), the distributions may look like the following: However when you have continuous outcomes (e.g. the weight of your baby), you will get a probability distribution that more resembles a curve (depending on how large your interval widths are). As you make the interval widths infinitely small (i.e. to the point where you smooth out this curve), the probability set will form a 'probability density curve' - make no mistake, these represent the same thing, however the 'probability density curve' would moreso be an interpretation (i.e. model) of the data, rather than a representation of the data itself. Note the sum of all probabilities must equal to 1 in a probability distribution (i.e. the Area under the curve) One common probability distribution you will see is the Normal Distribution","title":"Probability distribution"},{"location":"Biostatistics/Medical%20Statistics/Sample%20Size%20and%20Power/","text":"Sample size and power Background Sample sizes are important in determining the expected cost of studies - they need to be calculated prior to starting studies (otherwise you could end up with lots of data which is meaningless - a massive waste of money!) Calculating sample size for a population mean If we wish to estimate population mean, we can use the formula for standard error of the mean : \\(\\text{SE}_{mean} = \\frac{s}{\\sqrt(n)}\\) , where \\(s\\) is the standard deviation of the population Using this formula, we can easily calculate the sample size \\(n\\) if we know the SD and how tight we want our confidence intervals (thus the value of SE) Calculating sample size for a population proportion Calculating sample size for significance testing","title":"Sample size and power"},{"location":"Biostatistics/Medical%20Statistics/Sample%20Size%20and%20Power/#sample-size-and-power","text":"","title":"Sample size and power"},{"location":"Biostatistics/Medical%20Statistics/Sample%20Size%20and%20Power/#background","text":"Sample sizes are important in determining the expected cost of studies - they need to be calculated prior to starting studies (otherwise you could end up with lots of data which is meaningless - a massive waste of money!)","title":"Background"},{"location":"Biostatistics/Medical%20Statistics/Sample%20Size%20and%20Power/#calculating-sample-size-for-a-population-mean","text":"If we wish to estimate population mean, we can use the formula for standard error of the mean : \\(\\text{SE}_{mean} = \\frac{s}{\\sqrt(n)}\\) , where \\(s\\) is the standard deviation of the population Using this formula, we can easily calculate the sample size \\(n\\) if we know the SD and how tight we want our confidence intervals (thus the value of SE)","title":"Calculating sample size for a population mean"},{"location":"Biostatistics/Medical%20Statistics/Sample%20Size%20and%20Power/#calculating-sample-size-for-a-population-proportion","text":"","title":"Calculating sample size for a population proportion"},{"location":"Biostatistics/Medical%20Statistics/Sample%20Size%20and%20Power/#calculating-sample-size-for-significance-testing","text":"","title":"Calculating sample size for significance testing"},{"location":"Biostatistics/Medical%20Statistics/Simple%20Linear%20Regression/","text":"","title":"Simple Linear Regression"},{"location":"Biostatistics/Medical%20Statistics/Small%20Sample%20Tests/","text":"","title":"Small Sample Tests"},{"location":"Biostatistics/Medical%20Statistics/Spearman%27s%20rank%20correlation%20coefficient/","text":"Spearman's rank correlation coefficient","title":"Spearman's rank correlation coefficient"},{"location":"Biostatistics/Medical%20Statistics/Spearman%27s%20rank%20correlation%20coefficient/#spearmans-rank-correlation-coefficient","text":"","title":"Spearman's rank correlation coefficient"},{"location":"Biostatistics/Medical%20Statistics/Wilcoxon%20matched%20pairs%20test/","text":"Wilcoxon matched pairs test","title":"Wilcoxon matched pairs test"},{"location":"Biostatistics/Medical%20Statistics/Wilcoxon%20matched%20pairs%20test/#wilcoxon-matched-pairs-test","text":"","title":"Wilcoxon matched pairs test"},{"location":"Biostatistics/Meta-analysis/Components%20of%20the%20meta-analysis/","text":"Components of the meta-analysis Background Meta-analysis is used to summarise the results of several studies into a single estimate usually it estimates the effect size (of a treatment or a risk factor) Meta-analyses are USUALY presented in systematic reviews (called systematic reviews with meta-analysis), however not all systematic reviews will contain a meta-analysis meta-analyses can also be performed outside the systematic review Considerations before starting There should be >1 study being meta-analysed There must be minimal clinical heterogeneity e.g. populations involved, interventions, risk factors should be sufficiently similar between the studies this is a judgement call made by the researcher outcome variables need to be provided so they can be combined we need to be able to retrieve the data What type of data we're working with intervention studies (e.g. RCTs) - treatment effect size Epidemiological studies (case-control and cohort): Relative risk Diagnostic studies: Sn, Sp, PPV Population estimates (E.g. prevalence) Components Pooling of estimates - Pooling estimates see Fixed effect model and Random effects model Visualisation of the summary statistic - the Forest Plot Assessment of Study Heterogeneity","title":"Components of the meta-analysis"},{"location":"Biostatistics/Meta-analysis/Components%20of%20the%20meta-analysis/#components-of-the-meta-analysis","text":"","title":"Components of the meta-analysis"},{"location":"Biostatistics/Meta-analysis/Components%20of%20the%20meta-analysis/#background","text":"Meta-analysis is used to summarise the results of several studies into a single estimate usually it estimates the effect size (of a treatment or a risk factor) Meta-analyses are USUALY presented in systematic reviews (called systematic reviews with meta-analysis), however not all systematic reviews will contain a meta-analysis meta-analyses can also be performed outside the systematic review","title":"Background"},{"location":"Biostatistics/Meta-analysis/Components%20of%20the%20meta-analysis/#considerations-before-starting","text":"There should be >1 study being meta-analysed There must be minimal clinical heterogeneity e.g. populations involved, interventions, risk factors should be sufficiently similar between the studies this is a judgement call made by the researcher outcome variables need to be provided so they can be combined we need to be able to retrieve the data What type of data we're working with intervention studies (e.g. RCTs) - treatment effect size Epidemiological studies (case-control and cohort): Relative risk Diagnostic studies: Sn, Sp, PPV Population estimates (E.g. prevalence)","title":"Considerations before starting"},{"location":"Biostatistics/Meta-analysis/Components%20of%20the%20meta-analysis/#components","text":"Pooling of estimates - Pooling estimates see Fixed effect model and Random effects model Visualisation of the summary statistic - the Forest Plot Assessment of Study Heterogeneity","title":"Components"},{"location":"Biostatistics/Meta-analysis/Fixed%20effect%20model/","text":"Fixed effect model The fixed effect model is the simplest meta-analysis model available Mathematics of the fixed-effect model We first define weights to reflect the importance of each included study - this is done using the inverse variance method \\( \\(\\begin{aligned} \\text{weight} &= \\frac{1}{\\text{variance of trial}} \\\\ &=\\frac{1}{\\text{standard error squared}} \\end{aligned}\\) \\) Each trial difference is multiplied by its weight, added, then divided by the sum of weights \\( \\(\\text{common estimate} = {\\frac{\\text{trial difference}\\times \\text{weight}}{\\Sigma\\text{weights}}}\\) \\) We expect studies with high variance (thus high standard error squared) to be from studies with low amounts of information - therefore these studies are weighed less If studies had more information , they would therefore have a lowest standard error, and thus be weighed more Having found the pooled estimate, we then calculate the standard error and confidence interval for it We then test the null hypothesis that the pooled effect is zero","title":"Fixed effect model"},{"location":"Biostatistics/Meta-analysis/Fixed%20effect%20model/#fixed-effect-model","text":"The fixed effect model is the simplest meta-analysis model available","title":"Fixed effect model"},{"location":"Biostatistics/Meta-analysis/Fixed%20effect%20model/#mathematics-of-the-fixed-effect-model","text":"We first define weights to reflect the importance of each included study - this is done using the inverse variance method \\( \\(\\begin{aligned} \\text{weight} &= \\frac{1}{\\text{variance of trial}} \\\\ &=\\frac{1}{\\text{standard error squared}} \\end{aligned}\\) \\) Each trial difference is multiplied by its weight, added, then divided by the sum of weights \\( \\(\\text{common estimate} = {\\frac{\\text{trial difference}\\times \\text{weight}}{\\Sigma\\text{weights}}}\\) \\) We expect studies with high variance (thus high standard error squared) to be from studies with low amounts of information - therefore these studies are weighed less If studies had more information , they would therefore have a lowest standard error, and thus be weighed more Having found the pooled estimate, we then calculate the standard error and confidence interval for it We then test the null hypothesis that the pooled effect is zero","title":"Mathematics of the fixed-effect model"},{"location":"Biostatistics/Meta-analysis/Forest%20Plot/","text":"Forest Plot","title":"Forest Plot"},{"location":"Biostatistics/Meta-analysis/Forest%20Plot/#forest-plot","text":"","title":"Forest Plot"},{"location":"Biostatistics/Meta-analysis/Pooling%20estimates/","text":"Pooling estimates Background Meta-analysis primarily relies on estimate pooling. Most meta-analyses pool estimates using only two components: The summary statistic The standard error of the summary statistic The standard error is necessary as without it, we would use a single value to represent each study's value - we would then assume all studies are of equal value. Effect models The method we used for pooling estimates are called the 'Effect models'. There are two general effect models (each with their own sub-theories) used: Fixed effect model This model assumes only one effect which is estimated by each study Random effects model this assumes that the studies vary in what they estimate, and that we want a mean value This model allows each study to estimate a slightly a different effect","title":"Pooling estimates"},{"location":"Biostatistics/Meta-analysis/Pooling%20estimates/#pooling-estimates","text":"","title":"Pooling estimates"},{"location":"Biostatistics/Meta-analysis/Pooling%20estimates/#background","text":"Meta-analysis primarily relies on estimate pooling. Most meta-analyses pool estimates using only two components: The summary statistic The standard error of the summary statistic The standard error is necessary as without it, we would use a single value to represent each study's value - we would then assume all studies are of equal value.","title":"Background"},{"location":"Biostatistics/Meta-analysis/Pooling%20estimates/#effect-models","text":"The method we used for pooling estimates are called the 'Effect models'. There are two general effect models (each with their own sub-theories) used: Fixed effect model This model assumes only one effect which is estimated by each study Random effects model this assumes that the studies vary in what they estimate, and that we want a mean value This model allows each study to estimate a slightly a different effect","title":"Effect models"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/","text":"Publication bias Funnel plot Statistical tests of funnel plot assymetry Begg and Mazumdar's test Egger's test Tang and Liu's variant on Egger's test Correcting for publication bias Trim and full method (Duval and Tweedie)","title":"Publication bias"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#publication-bias","text":"","title":"Publication bias"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#funnel-plot","text":"","title":"Funnel plot"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#statistical-tests-of-funnel-plot-assymetry","text":"","title":"Statistical tests of funnel plot assymetry"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#begg-and-mazumdars-test","text":"","title":"Begg and Mazumdar's test"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#eggers-test","text":"","title":"Egger's test"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#tang-and-lius-variant-on-eggers-test","text":"","title":"Tang and Liu's variant on Egger's test"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#correcting-for-publication-bias","text":"","title":"Correcting for publication bias"},{"location":"Biostatistics/Meta-analysis/Publication%20bias/#trim-and-full-method-duval-and-tweedie","text":"","title":"Trim and full method (Duval and Tweedie)"},{"location":"Biostatistics/Meta-analysis/Random%20effects%20model/","text":"Random effects model","title":"Random effects model"},{"location":"Biostatistics/Meta-analysis/Random%20effects%20model/#random-effects-model","text":"","title":"Random effects model"},{"location":"Biostatistics/Meta-analysis/Statistical%20heterogeneity/","text":"Statistical heterogeneity Identifying statistical heterogeneity Test the null hypothesis that all studies all have the same treatment effect in the population The difference between the observed treatment effect and the pooled treatment effect is squared, divided by the variance of the study effect, then added together $$\\begin{aligned} \\text{diff} &= \\text{effect} {observed, trial} - \\text{effect} \\ Q &= \\Sigma \\ (\\text{diff}_{\\text{each study}}^2 \\div \\sigma) \\end{aligned} $$ - This value ( \\(Q\\) ) gives a \\(\\chi^2\\) test with degrees of freedom = number of studies - 1 - That is, the \\(Q\\) value is the \\(\\chi^2\\) value 2. Straight line test - All confidence intervals overlap - Common estimates all fall within the overlapping confidence intervals Interpreting the \\(\\chi^2\\) test for heterogeneity If p < 0.05, by our standard definition this would mean there is evidence of heterogeneity Therefore if p > 0.05, then we can say there is no heterogeneity however in small sample studies, due to the low power of the test, it may be valid to accept a larger value of P as being significant Some studies have opted to use p < 0.1 as their cutoff Measuring heterogeneity using the \\(I^2\\) test","title":"Statistical heterogeneity"},{"location":"Biostatistics/Meta-analysis/Statistical%20heterogeneity/#statistical-heterogeneity","text":"","title":"Statistical heterogeneity"},{"location":"Biostatistics/Meta-analysis/Statistical%20heterogeneity/#identifying-statistical-heterogeneity","text":"Test the null hypothesis that all studies all have the same treatment effect in the population The difference between the observed treatment effect and the pooled treatment effect is squared, divided by the variance of the study effect, then added together $$\\begin{aligned} \\text{diff} &= \\text{effect} {observed, trial} - \\text{effect} \\ Q &= \\Sigma \\ (\\text{diff}_{\\text{each study}}^2 \\div \\sigma) \\end{aligned} $$ - This value ( \\(Q\\) ) gives a \\(\\chi^2\\) test with degrees of freedom = number of studies - 1 - That is, the \\(Q\\) value is the \\(\\chi^2\\) value 2. Straight line test - All confidence intervals overlap - Common estimates all fall within the overlapping confidence intervals","title":"Identifying statistical heterogeneity"},{"location":"Biostatistics/Meta-analysis/Statistical%20heterogeneity/#interpreting-the-chi2-test-for-heterogeneity","text":"If p < 0.05, by our standard definition this would mean there is evidence of heterogeneity Therefore if p > 0.05, then we can say there is no heterogeneity however in small sample studies, due to the low power of the test, it may be valid to accept a larger value of P as being significant Some studies have opted to use p < 0.1 as their cutoff","title":"Interpreting the \\(\\chi^2\\) test for heterogeneity"},{"location":"Biostatistics/Meta-analysis/Statistical%20heterogeneity/#measuring-heterogeneity-using-the-i2-test","text":"","title":"Measuring heterogeneity using the \\(I^2\\) test"},{"location":"Biostatistics/Meta-analysis/Study%20Heterogeneity/","text":"Study Heterogeneity Background Study heterogeneity regards differences in the studies involved in our meta-analysis. There are two main forms of heterogeneity Clinical heterogeneity This occurs when the study design, participants, interventions, outcomes are different When there is clinical heterogeneity, we need to consider if the meta-analysis we wish to perform is even valid This is a judgement call - done by reading through the included papers Statistical heterogeneity This is a statistical calculation of the size of variation in outcome variable between studies. This is determined purely on statistical/mathematical grounds through calculations Clinically homogenous studies can still have statistical hetergeneity What to do when there is heterogeneity Some options available include: Do not pool the study estimates - just carry out a narrative review Ignore the heterogeneity and assume the underlying effects are the same - this can overestimate the effect size (and further narrow the confidence interval) We can explore the heterogeneity, try to explain it, and remove it We can allow for heterogeneity and estimate a larger confidence interval using a random effects model","title":"Study Heterogeneity"},{"location":"Biostatistics/Meta-analysis/Study%20Heterogeneity/#study-heterogeneity","text":"","title":"Study Heterogeneity"},{"location":"Biostatistics/Meta-analysis/Study%20Heterogeneity/#background","text":"Study heterogeneity regards differences in the studies involved in our meta-analysis. There are two main forms of heterogeneity Clinical heterogeneity This occurs when the study design, participants, interventions, outcomes are different When there is clinical heterogeneity, we need to consider if the meta-analysis we wish to perform is even valid This is a judgement call - done by reading through the included papers Statistical heterogeneity This is a statistical calculation of the size of variation in outcome variable between studies. This is determined purely on statistical/mathematical grounds through calculations Clinically homogenous studies can still have statistical hetergeneity","title":"Background"},{"location":"Biostatistics/Meta-analysis/Study%20Heterogeneity/#what-to-do-when-there-is-heterogeneity","text":"Some options available include: Do not pool the study estimates - just carry out a narrative review Ignore the heterogeneity and assume the underlying effects are the same - this can overestimate the effect size (and further narrow the confidence interval) We can explore the heterogeneity, try to explain it, and remove it We can allow for heterogeneity and estimate a larger confidence interval using a random effects model","title":"What to do when there is heterogeneity"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/For%20loop/","text":"For loop Background A fundamental operation in programming, the for loop lets you iterate through an object/list and perform operations to individual elements Structure for (val in sequence){ statement } Example for (row in 1:nrow(data_bp_prior2019)){ sbp = data_bp_prior2019[row]$sbp dbp = data_bp_prior2019[row]$dbp htnStatus = c(htnStatus, check_hypertensive(sbp, dbp)) }","title":"For loop"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/For%20loop/#for-loop","text":"","title":"For loop"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/For%20loop/#background","text":"A fundamental operation in programming, the for loop lets you iterate through an object/list and perform operations to individual elements","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/For%20loop/#structure","text":"for (val in sequence){ statement }","title":"Structure"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/For%20loop/#example","text":"for (row in 1:nrow(data_bp_prior2019)){ sbp = data_bp_prior2019[row]$sbp dbp = data_bp_prior2019[row]$dbp htnStatus = c(htnStatus, check_hypertensive(sbp, dbp)) }","title":"Example"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/If-else%20statement/","text":"If-statement Structure The if statement is used if you want to do a simple check if (test_expression) { statement } The If-else statement is used for binary checks (if it is A OR B) if (test_expression) { statement1 } else { statement2 } The If-elseif-else statement is used if you want to check against multiple possibilities of a value (or multiple situations) if ( test_expression1) { statement1 } else if ( test_expression2) { statement2 } else if ( test_expression3) { statement3 } else { statement4 } Example check_hypertensive <- function(sbp, dbp) { if (is.na(sbp) | is.na(dbp)) { return(2) } if(sbp >= 140 | dbp >= 90) { return (1) } else { return(0) } }","title":"If-statement"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/If-else%20statement/#if-statement","text":"","title":"If-statement"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/If-else%20statement/#structure","text":"The if statement is used if you want to do a simple check if (test_expression) { statement } The If-else statement is used for binary checks (if it is A OR B) if (test_expression) { statement1 } else { statement2 } The If-elseif-else statement is used if you want to check against multiple possibilities of a value (or multiple situations) if ( test_expression1) { statement1 } else if ( test_expression2) { statement2 } else if ( test_expression3) { statement3 } else { statement4 }","title":"Structure"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/If-else%20statement/#example","text":"check_hypertensive <- function(sbp, dbp) { if (is.na(sbp) | is.na(dbp)) { return(2) } if(sbp >= 140 | dbp >= 90) { return (1) } else { return(0) } }","title":"Example"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Logical%20operators/","text":"Logical operators Operator Description < Less than <= Less than or equal to > greater than >= Greater than or equal to == Exactly equal to != Not equal to !x NOT x x|y x OR y x&y x AND y isTRUE(x) if X is TRUE","title":"Logical operators"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Logical%20operators/#logical-operators","text":"Operator Description < Less than <= Less than or equal to > greater than >= Greater than or equal to == Exactly equal to != Not equal to !x NOT x x|y x OR y x&y x AND y isTRUE(x) if X is TRUE","title":"Logical operators"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/","text":"Quick intro to R and R-studio Background R is a solid statistical application that allows you to script around Starting a script It is a good habit to write scripts with some information/background at the top to describe its function - for example: # Author: Name # Date: Today # Purpose: Write and run my first R program chol <- read.csv(\"Y:\\\\Biostats\\\\PUBH5217 Regression modelling\\\\Data\\\\2020\\\\chol.csv\") View(chol) summary(chol) Installing install.packages(\"<packagename>\") Installs packages Loading library(<packagename>) Loads the package Accessing a column data$columnname Variable types Variable type definition Character Text or string Integer Whole number (continuous variable in R) Numeric Number with decimal places (continuous) Logical Boolean i.e. TRUE or FALSE Factor Categorical variable, with corresponding 'labels' Date e.g. date of birth Missing Missing variables are represented by NA Not a number Impossible values (e.g. dividing by 0) gives you Not A Number or NaN","title":"Quick intro to R and R-studio"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#quick-intro-to-r-and-r-studio","text":"","title":"Quick intro to R and R-studio"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#background","text":"R is a solid statistical application that allows you to script around","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#starting-a-script","text":"It is a good habit to write scripts with some information/background at the top to describe its function - for example: # Author: Name # Date: Today # Purpose: Write and run my first R program chol <- read.csv(\"Y:\\\\Biostats\\\\PUBH5217 Regression modelling\\\\Data\\\\2020\\\\chol.csv\") View(chol) summary(chol)","title":"Starting a script"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#installing","text":"install.packages(\"<packagename>\") Installs packages","title":"Installing"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#loading","text":"library(<packagename>) Loads the package","title":"Loading"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#accessing-a-column","text":"data$columnname","title":"Accessing a column"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Quick%20Intro%20to%20R/#variable-types","text":"Variable type definition Character Text or string Integer Whole number (continuous variable in R) Numeric Number with decimal places (continuous) Logical Boolean i.e. TRUE or FALSE Factor Categorical variable, with corresponding 'labels' Date e.g. date of birth Missing Missing variables are represented by NA Not a number Impossible values (e.g. dividing by 0) gives you Not A Number or NaN","title":"Variable types"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/","text":"R functions Background R functions are useful if you need to perform something in a loop. Functions are important in object oriented programming (OOP) as they allow re-usability and simplicity of code Building a function Structure function_name <- function(arg_1, arg_2, ...) { Function body return(value) } Components: Function Name \u2212 This is the actual name of the function. It is stored in R environment as an object with this name. Arguments \u2212 An argument is a placeholder. When a function is invoked, you pass a value to the argument. Arguments are optional; that is, a function may contain no arguments. Also arguments can have default values. Function Body \u2212 The function body contains a collection of statements that defines what the function does. Return Value \u2212 The return value of a function is the last expression in the function body to be evaluated. Examples ## Check hypertensive function - checks if a set of SBP or DBP are defined as hypertensive check_hypertensive <- function(sbp, dbp) { if(sbp >= 140 | dbp >= 90) { return (TRUE) } else{ return(FALSE) } } Loading a function Functions need to be loaded from the file you've built them into Example source('Functions/HTNfunctions.R') check_hypertensive(100, 80)","title":"R functions"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#r-functions","text":"","title":"R functions"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#background","text":"R functions are useful if you need to perform something in a loop. Functions are important in object oriented programming (OOP) as they allow re-usability and simplicity of code","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#building-a-function","text":"","title":"Building a function"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#structure","text":"function_name <- function(arg_1, arg_2, ...) { Function body return(value) } Components: Function Name \u2212 This is the actual name of the function. It is stored in R environment as an object with this name. Arguments \u2212 An argument is a placeholder. When a function is invoked, you pass a value to the argument. Arguments are optional; that is, a function may contain no arguments. Also arguments can have default values. Function Body \u2212 The function body contains a collection of statements that defines what the function does. Return Value \u2212 The return value of a function is the last expression in the function body to be evaluated.","title":"Structure"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#examples","text":"## Check hypertensive function - checks if a set of SBP or DBP are defined as hypertensive check_hypertensive <- function(sbp, dbp) { if(sbp >= 140 | dbp >= 90) { return (TRUE) } else{ return(FALSE) } }","title":"Examples"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#loading-a-function","text":"Functions need to be loaded from the file you've built them into","title":"Loading a function"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/R%20functions/#example","text":"source('Functions/HTNfunctions.R') check_hypertensive(100, 80)","title":"Example"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Saving%20serialised%20data/","text":"Saving serialised data Background Data generated in R can be saved (e.g. dataframes, lists, etc.) in a serialised format - this is a ?lossless means of storage which allows you to store the oriignal data is as accurate a form as possible. Data can also be saved in .csv format, or even .txt, which allows access to the data via other applications (e.g. MS Excel, notepad, etc.). Code saveRDS(x, file = \"myvector_serialized.rds\") Example saveRDS(includedPatients, file = \"includedPatients.rds\") Loading the data Data can then be loaded in the following manner: x <- readRDS(\"myvector_serialized.rds\")","title":"Saving serialised data"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Saving%20serialised%20data/#saving-serialised-data","text":"","title":"Saving serialised data"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Saving%20serialised%20data/#background","text":"Data generated in R can be saved (e.g. dataframes, lists, etc.) in a serialised format - this is a ?lossless means of storage which allows you to store the oriignal data is as accurate a form as possible. Data can also be saved in .csv format, or even .txt, which allows access to the data via other applications (e.g. MS Excel, notepad, etc.).","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Saving%20serialised%20data/#code","text":"saveRDS(x, file = \"myvector_serialized.rds\")","title":"Code"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Saving%20serialised%20data/#example","text":"saveRDS(includedPatients, file = \"includedPatients.rds\")","title":"Example"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Saving%20serialised%20data/#loading-the-data","text":"Data can then be loaded in the following manner: x <- readRDS(\"myvector_serialized.rds\")","title":"Loading the data"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Vector%20operations/","text":"Vector operations Make a new vector vector = c(a, b, c) Append to vector vector = c(vector, newVal)","title":"Vector operations"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Vector%20operations/#vector-operations","text":"","title":"Vector operations"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Vector%20operations/#make-a-new-vector","text":"vector = c(a, b, c)","title":"Make a new vector"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20R/Vector%20operations/#append-to-vector","text":"vector = c(vector, newVal)","title":"Append to vector"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Assessing%20missingness/","text":"Assessing missingness Background Missingness data patterns should be assessed - this can be done in R Packages mice package - multiple imputation by chained equations Functions md.pattern([data], rotate.names=TRUE) builds a missing data plot to determine if missingness is monotonic or non-monotonic","title":"Assessing missingness"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Assessing%20missingness/#assessing-missingness","text":"","title":"Assessing missingness"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Assessing%20missingness/#background","text":"Missingness data patterns should be assessed - this can be done in R","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Assessing%20missingness/#packages","text":"mice package - multiple imputation by chained equations","title":"Packages"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Assessing%20missingness/#functions","text":"md.pattern([data], rotate.names=TRUE) builds a missing data plot to determine if missingness is monotonic or non-monotonic","title":"Functions"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/","text":"Data checking Questions to consider Questions you need to ask yourself: Does the variable have missing values? How many are missing (i.e. what proportion)? Does any variable have many missing values? Should we continue to use that variable? Does it make sense to do so? Do we impute ( Data imputation ) the missing variables if we include it? Is the variable correctly classified e.g. continuous vs categorical Are all observations valid and plausible Check minimum and maximum values Check categories Recode implausible values to imssing Examine distribution (shape) of variable Do we need to transform or modify the variable? e.g. do we need to log transform to make a variable normally distributed? For categorical variables Frequency tables or bar charts For continuous variables Plots (e.g. histograms, boxplots) Appropriate summary statistics (minimum and max values) Recoding data Recoding single variables can be done with data$column[itemnumber] \u2190 newValue Recoding multiple variables (using a boolean) data$column[data$column > value] \u2190 newValue Recoding as a factor This is done is column is coded as a certain variable (e.g. an integer) where it should be coded as a factor (e.g. 0, 1, 2, 3,4 represent 'strongly disagree', 'disagree', 'neutral', 'agree', 'strongly agree') data$column <- factor(data$column, labels = c(\"Strongly disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly agree\")) Intepreting this function: factor(data$column) converts the column into 'factors' this is then assigned ( <- ) into the original column labels = c(\"...\") allows you to set a series of labels in that order Transforming a variable # transform height from cm to m chol$HEIGHT_M <- chol$HEIGHT / 100 # calculate bmi (body mass index) chol$bmi <- chol$WEIGHT / chol$HEIGHT_M**2 chol$LOGCHOL <- log(chol$CHOL)","title":"Data checking"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#data-checking","text":"","title":"Data checking"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#questions-to-consider","text":"Questions you need to ask yourself: Does the variable have missing values? How many are missing (i.e. what proportion)? Does any variable have many missing values? Should we continue to use that variable? Does it make sense to do so? Do we impute ( Data imputation ) the missing variables if we include it? Is the variable correctly classified e.g. continuous vs categorical Are all observations valid and plausible Check minimum and maximum values Check categories Recode implausible values to imssing Examine distribution (shape) of variable Do we need to transform or modify the variable? e.g. do we need to log transform to make a variable normally distributed?","title":"Questions to consider"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#for-categorical-variables","text":"Frequency tables or bar charts","title":"For categorical variables"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#for-continuous-variables","text":"Plots (e.g. histograms, boxplots) Appropriate summary statistics (minimum and max values)","title":"For continuous variables"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#recoding-data","text":"Recoding single variables can be done with data$column[itemnumber] \u2190 newValue Recoding multiple variables (using a boolean) data$column[data$column > value] \u2190 newValue","title":"Recoding data"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#recoding-as-a-factor","text":"This is done is column is coded as a certain variable (e.g. an integer) where it should be coded as a factor (e.g. 0, 1, 2, 3,4 represent 'strongly disagree', 'disagree', 'neutral', 'agree', 'strongly agree') data$column <- factor(data$column, labels = c(\"Strongly disagree\", \"Disagree\", \"Neutral\", \"Agree\", \"Strongly agree\")) Intepreting this function: factor(data$column) converts the column into 'factors' this is then assigned ( <- ) into the original column labels = c(\"...\") allows you to set a series of labels in that order","title":"Recoding as a factor"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Data%20checking/#transforming-a-variable","text":"# transform height from cm to m chol$HEIGHT_M <- chol$HEIGHT / 100 # calculate bmi (body mass index) chol$bmi <- chol$WEIGHT / chol$HEIGHT_M**2 chol$LOGCHOL <- log(chol$CHOL)","title":"Transforming a variable"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/","text":"Exploratory data analysis Background Before you start research with a dataset you need to understand the shape of your dataset (and its components). Exploratory data analysis (EDA) gives you insight into what data you're dealing with, and what questions you can ask of it. It is a very practical and systematic approach to looking at your data, and can allow you to find issues with the dataset. Packages for exploratory data analysis skimr https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html To use this package: library(skimr) skim(data) Useful features - skim(dataset) - Gives summary statistics for the whole dataset summarytools Gives access to additional tools library(summarytools) Useful features - freq(data$column) - Frequency table for the column of interest - Note the %valid column ignores missing values when calculating frequences and percentages, whilst %Total includes missing values as a category Selecting rows of data based on a conditional tidyverse Function: filter(data, condition) dplyr - Function:","title":"Exploratory data analysis"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#exploratory-data-analysis","text":"","title":"Exploratory data analysis"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#background","text":"Before you start research with a dataset you need to understand the shape of your dataset (and its components). Exploratory data analysis (EDA) gives you insight into what data you're dealing with, and what questions you can ask of it. It is a very practical and systematic approach to looking at your data, and can allow you to find issues with the dataset.","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#packages-for-exploratory-data-analysis","text":"","title":"Packages for exploratory data analysis"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#skimr","text":"https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html To use this package: library(skimr) skim(data) Useful features - skim(dataset) - Gives summary statistics for the whole dataset","title":"skimr"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#summarytools","text":"Gives access to additional tools library(summarytools) Useful features - freq(data$column) - Frequency table for the column of interest - Note the %valid column ignores missing values when calculating frequences and percentages, whilst %Total includes missing values as a category","title":"summarytools"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#selecting-rows-of-data-based-on-a-conditional","text":"","title":"Selecting rows of data based on a conditional"},{"location":"Biostatistics/Practical%20Biostatistics/Basic%20Skills/Exploratory%20data%20analysis/#tidyverse","text":"Function: filter(data, condition) dplyr - Function:","title":"tidyverse"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Approach%20to%20missing%20values/","text":"Approach to missing values Background Due to the way we record data or keep track of it, variables can be missing. This comes with a few issues - notably: If variables are missing, we have less resolution/detail in our data Approaches Missing data can be dealt with a few ways. These all comes with advantages and disadvantages. These are some simple approaches (with relevant discussions to be considered): Delete rows with missing data Delete columns with a high enough proportion of missing data Data imputation Imputation of data is very effective, however there are multiple approaches in of itself. See the link above for an approach to the methods.","title":"Approach to missing values"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Approach%20to%20missing%20values/#approach-to-missing-values","text":"","title":"Approach to missing values"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Approach%20to%20missing%20values/#background","text":"Due to the way we record data or keep track of it, variables can be missing. This comes with a few issues - notably: If variables are missing, we have less resolution/detail in our data","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Approach%20to%20missing%20values/#approaches","text":"Missing data can be dealt with a few ways. These all comes with advantages and disadvantages. These are some simple approaches (with relevant discussions to be considered): Delete rows with missing data Delete columns with a high enough proportion of missing data Data imputation Imputation of data is very effective, however there are multiple approaches in of itself. See the link above for an approach to the methods.","title":"Approaches"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Reasonable%20variable%20ranges/","text":"Reasonable variable ranges Background When cleaning data, you will come across data which is not feasible - these can be outliers, or mistyped variables, etc. Common variables Blood pressure (Systolic) Blood pressure (Diastolic) Age Height Weight","title":"Reasonable variable ranges"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Reasonable%20variable%20ranges/#reasonable-variable-ranges","text":"","title":"Reasonable variable ranges"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Reasonable%20variable%20ranges/#background","text":"When cleaning data, you will come across data which is not feasible - these can be outliers, or mistyped variables, etc.","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Cleaning%20data/Reasonable%20variable%20ranges/#common-variables","text":"Blood pressure (Systolic) Blood pressure (Diastolic) Age Height Weight","title":"Common variables"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Causal%20diagrams/","text":"Causal diagrams References Greenland and Robins","title":"Causal diagrams"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Causal%20diagrams/#causal-diagrams","text":"","title":"Causal diagrams"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Causal%20diagrams/#references","text":"Greenland and Robins","title":"References"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/","text":"Table 1 Background Table 1 is the characteristics table of the study population. This is used in all cohort studies (Prospective and retrospective) as well as Clinical trials as it demonstrates the initiating (baseline) characteristics of the included participants. Table 1 helps the reader identify issues in internal validity including: Confounding Selection bias Measurement errors Features of a Table 1 Table 1: Baseline characteristics of patients These tables should have the following columns: The characteristic/variable column (i.e. what the characteristic is) You can further subgroup each of the characteristics if you'd like - e.g. 'Age group' can be subgrouped into <50, 50-69, 60-69, >70, etc. The group(s) of interest e.g. the 'comparator' and the 'intervention' would be two separate columns Stratifying by this 'exposure' can identify confounders alteratively you can have a single 'total' column This data is provided typically as n(%) for categorical variables, mean(SD) or mean(IQR) for continuous variables Additional columns can be used e.g. values for an external population - this can be used to support the external validity if your data Additional tips Include (N) in the column header Round percentages to whole numbers Mean(SD) is good for continuous variables when the data is normally distributed , however showing range/IQR is better if not Consider shading/crossing out a cell if the value is absent - otherwise the reader might confuse it with a missing cell (OPTIONAL) The P-test value Occasionally you may present the P-test value theoretically this is used for assessment of confounders However, confounders should only really be when there is a hypothesized confounding role using causal theory However note that in a randomised clinical trial, the baseline assumption is that the randomisation is undertaken appropriately and therefore any differences in distribution are due to chance - therefore the P-test would be meaningless (as the P-value is an indication for how likely the difference is due to chance, of which that difference is completely due to change due to the nature of randomisation). Dealing with Missing Data Example From Hayes-Larson et al (2019) Relevant packages R and RStudio tableone https://cran.r-project.org/web/packages/tableone/tableone.pdf References Thomas Love's course notes for Data Science for Biological, Medical and Health Research Hayes-Larson et al (2019) - Who is in this study, anyway? Guidelines for a useful Table 1","title":"Table 1"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#table-1","text":"","title":"Table 1"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#background","text":"Table 1 is the characteristics table of the study population. This is used in all cohort studies (Prospective and retrospective) as well as Clinical trials as it demonstrates the initiating (baseline) characteristics of the included participants. Table 1 helps the reader identify issues in internal validity including: Confounding Selection bias Measurement errors","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#features-of-a-table-1","text":"Table 1: Baseline characteristics of patients These tables should have the following columns: The characteristic/variable column (i.e. what the characteristic is) You can further subgroup each of the characteristics if you'd like - e.g. 'Age group' can be subgrouped into <50, 50-69, 60-69, >70, etc. The group(s) of interest e.g. the 'comparator' and the 'intervention' would be two separate columns Stratifying by this 'exposure' can identify confounders alteratively you can have a single 'total' column This data is provided typically as n(%) for categorical variables, mean(SD) or mean(IQR) for continuous variables Additional columns can be used e.g. values for an external population - this can be used to support the external validity if your data Additional tips Include (N) in the column header Round percentages to whole numbers Mean(SD) is good for continuous variables when the data is normally distributed , however showing range/IQR is better if not Consider shading/crossing out a cell if the value is absent - otherwise the reader might confuse it with a missing cell (OPTIONAL) The P-test value Occasionally you may present the P-test value theoretically this is used for assessment of confounders However, confounders should only really be when there is a hypothesized confounding role using causal theory However note that in a randomised clinical trial, the baseline assumption is that the randomisation is undertaken appropriately and therefore any differences in distribution are due to chance - therefore the P-test would be meaningless (as the P-value is an indication for how likely the difference is due to chance, of which that difference is completely due to change due to the nature of randomisation).","title":"Features of a Table 1"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#dealing-with-missing-data","text":"","title":"Dealing with Missing Data"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#example","text":"From Hayes-Larson et al (2019)","title":"Example"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#relevant-packages","text":"","title":"Relevant packages"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#r-and-rstudio","text":"tableone https://cran.r-project.org/web/packages/tableone/tableone.pdf","title":"R and RStudio"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%201/#references","text":"Thomas Love's course notes for Data Science for Biological, Medical and Health Research Hayes-Larson et al (2019) - Who is in this study, anyway? Guidelines for a useful Table 1","title":"References"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202%20Fallacy/","text":"Table 2 Fallacy Background The Table 2 fallacy describes an issue in interpretability in table 2 (summary effects table) when the individual risk/odds ratios (derived fromthe beta coefficients) of multivariate models are all presented in the same table. This issue arises as the original analysis does not aim to look at the effect sizes of the included secondary variables. The presentation of these associatiates is post-hoc and statistically meaningless. An issue in interpretation Using the example from Westreich et al, we first consider a study looking at the effect of HIV on stroke. To calculate its direct effect, we control for confounders (the most prominent of which are smoking and age in this scenario). The mathematical model would therefore be: \\[ln(\\frac{\\text{Stroke}}{1-\\text{Stroke}}) = \\beta_0 + \\beta_1\\times\\text{HIV Status} + \\beta_2 \\times Age + \\beta_3 \\times \\text{Smoking Status} \\] Now if we intepret the \\(\\beta_1\\) value we can understand this the relative risk of HIV status on Stroke when controlling for Age and Smoking Status. However can we interpret the \\(\\beta_3\\) value as the relative risk of Smoking Status on Stroke (when controlling for HIV status and Age)? No - as the relationship between smoking status and stroke might have other relevant and important confounders. References Westreich and Greenland (2013)","title":"Table 2 Fallacy"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202%20Fallacy/#table-2-fallacy","text":"","title":"Table 2 Fallacy"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202%20Fallacy/#background","text":"The Table 2 fallacy describes an issue in interpretability in table 2 (summary effects table) when the individual risk/odds ratios (derived fromthe beta coefficients) of multivariate models are all presented in the same table. This issue arises as the original analysis does not aim to look at the effect sizes of the included secondary variables. The presentation of these associatiates is post-hoc and statistically meaningless.","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202%20Fallacy/#an-issue-in-interpretation","text":"Using the example from Westreich et al, we first consider a study looking at the effect of HIV on stroke. To calculate its direct effect, we control for confounders (the most prominent of which are smoking and age in this scenario). The mathematical model would therefore be: \\[ln(\\frac{\\text{Stroke}}{1-\\text{Stroke}}) = \\beta_0 + \\beta_1\\times\\text{HIV Status} + \\beta_2 \\times Age + \\beta_3 \\times \\text{Smoking Status} \\] Now if we intepret the \\(\\beta_1\\) value we can understand this the relative risk of HIV status on Stroke when controlling for Age and Smoking Status. However can we interpret the \\(\\beta_3\\) value as the relative risk of Smoking Status on Stroke (when controlling for HIV status and Age)? No - as the relationship between smoking status and stroke might have other relevant and important confounders.","title":"An issue in interpretation"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202%20Fallacy/#references","text":"Westreich and Greenland (2013)","title":"References"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202/","text":"Table 2 Background Issues with presentation Table 2 is prone to the aptly named Table 2 Fallacy .","title":"Table 2"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202/#table-2","text":"","title":"Table 2"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202/#background","text":"","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Table%202/#issues-with-presentation","text":"Table 2 is prone to the aptly named Table 2 Fallacy .","title":"Issues with presentation"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Tables%20and%20Figures/","text":"Tables and Figures Background Table and figures play an important role in helping the reader understand the distributions within populations and issues within studies. Here we discuss classic tables and figures found in medical research papers. Tables Table 1 , also known as the table of characteristics or Baseline characteristics table. Table 2 Of note is a discussion regarding the Table 2 Fallacy References Inskip et al (2017)","title":"Tables and Figures"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Tables%20and%20Figures/#tables-and-figures","text":"","title":"Tables and Figures"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Tables%20and%20Figures/#background","text":"Table and figures play an important role in helping the reader understand the distributions within populations and issues within studies. Here we discuss classic tables and figures found in medical research papers.","title":"Background"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Tables%20and%20Figures/#tables","text":"Table 1 , also known as the table of characteristics or Baseline characteristics table. Table 2 Of note is a discussion regarding the Table 2 Fallacy","title":"Tables"},{"location":"Biostatistics/Practical%20Biostatistics/Tables%20and%20figures/Tables%20and%20Figures/#references","text":"Inskip et al (2017)","title":"References"},{"location":"Clinical%20Epidemiology/","text":"Clinical Epidemiology Links Research Appraisal Research appraisal is important in understanding where research sits Research Design","title":"Introduction"},{"location":"Clinical%20Epidemiology/#clinical-epidemiology","text":"","title":"Clinical Epidemiology"},{"location":"Clinical%20Epidemiology/#links","text":"","title":"Links"},{"location":"Clinical%20Epidemiology/#research-appraisal","text":"Research appraisal is important in understanding where research sits","title":"Research Appraisal"},{"location":"Clinical%20Epidemiology/#research-design","text":"","title":"Research Design"},{"location":"Clinical%20Epidemiology/Research%20Appraisal/","text":"Research Appraisal afareafrae Hello","title":"Research Appraisal"},{"location":"Clinical%20Epidemiology/Research%20Appraisal/#research-appraisal","text":"afareafrae","title":"Research Appraisal"},{"location":"Clinical%20Epidemiology/Research%20Appraisal/#hello","text":"","title":"Hello"},{"location":"Clinical%20Epidemiology/Research%20Design/","text":"Research Design","title":"Research Design"},{"location":"Clinical%20Epidemiology/Research%20Design/#research-design","text":"","title":"Research Design"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/","text":"Observational studies Background At times observational studies are necessary - e.g. when the intervention (E.g. cigarette smoking) is known to cause harm, and we cannot apply such an intervention to our patient population without being ethically questionable observational studies can never be used to unequivocally determine a causation - they can however be used to determine correlation. Types of observational studies Case reports - a report of an interesting case (patient comes before the study) Case series - a report of similar cases Cross-sectional studies Cohort study Propsective cohort study Retrospective cohort study Case control studies Sampling in observational studies Samples in observational studies aim to represent the population in which the samples are taken from. As such, we must consider how sampling is performed: Convenience sampling - this is heavily biased and should almost never be used in quantitative studies Volunteering is an example of convenience sampling - this is based Quota sampling - sampling from the population based on distributions of categories of interest (e.g. age, sex, social class) this is problematic as (1) we do not know all relevant classifications, and (2) we might still conveniently sample based on friendly looking faces (making it convenience sampled on top in practice) and (3) we can only understand if we sampled appropriately by comparing against a sample without these drawbacks random sampling - sample obtained representation of a larger population - members chosen not based on their characteristics, but at random. simple random sampling - random participants are drawn (e.g. out of a hat) Quasi-random (systematic) sampling Methods of random sampling Simple random sampling Multi-stage random sampling Cluster sampling Stratified random sampling Response rate Response rate in a sample can range from 70-80% in a general population - reasons for lack of response can be: - participant is sick on dat of survey The effect of poor response rate may systematically bias us in either way","title":"Observational studies"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/#observational-studies","text":"","title":"Observational studies"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/#background","text":"At times observational studies are necessary - e.g. when the intervention (E.g. cigarette smoking) is known to cause harm, and we cannot apply such an intervention to our patient population without being ethically questionable observational studies can never be used to unequivocally determine a causation - they can however be used to determine correlation.","title":"Background"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/#types-of-observational-studies","text":"Case reports - a report of an interesting case (patient comes before the study) Case series - a report of similar cases Cross-sectional studies Cohort study Propsective cohort study Retrospective cohort study Case control studies","title":"Types of observational studies"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/#sampling-in-observational-studies","text":"Samples in observational studies aim to represent the population in which the samples are taken from. As such, we must consider how sampling is performed: Convenience sampling - this is heavily biased and should almost never be used in quantitative studies Volunteering is an example of convenience sampling - this is based Quota sampling - sampling from the population based on distributions of categories of interest (e.g. age, sex, social class) this is problematic as (1) we do not know all relevant classifications, and (2) we might still conveniently sample based on friendly looking faces (making it convenience sampled on top in practice) and (3) we can only understand if we sampled appropriately by comparing against a sample without these drawbacks random sampling - sample obtained representation of a larger population - members chosen not based on their characteristics, but at random. simple random sampling - random participants are drawn (e.g. out of a hat) Quasi-random (systematic) sampling","title":"Sampling in observational studies"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/#methods-of-random-sampling","text":"Simple random sampling Multi-stage random sampling Cluster sampling Stratified random sampling","title":"Methods of random sampling"},{"location":"Clinical%20Epidemiology/Research%20Design/Observational%20studies/#response-rate","text":"Response rate in a sample can range from 70-80% in a general population - reasons for lack of response can be: - participant is sick on dat of survey The effect of poor response rate may systematically bias us in either way","title":"Response rate"},{"location":"Clinical%20Epidemiology/Research%20Design/Qualitative%20research/Qualitative%20research/","text":"","title":"Qualitative research"},{"location":"EBM%20podcast/","text":"","title":"Index"},{"location":"Healthcare%20Economics/Hospital%20Funding/","text":"Hospital funding Hospital levels Local health networks (Local health districts) Groups/networks of neighbouring hospitals Cost for a hospital bed per day $1500 for a non-acute bed $2000 for an acute bed Money in hospitals state or territory health department sign agreements with LHDs - they are the 'purchaser' LHD is the 'service provider' https://www.sahealth.sa.gov.au/wps/wcm/connect/public+content/sa+health+internet/about+us/our+local+health+networks/service+level+agreements https://www.health.qld.gov.au/system-governance/health-system/managing/agreements-deeds Commonwealth reimbusement to the state ~45% of overall cost is reimbursed to the state Payment is based on Activity-Based Funding (ABF) reflection of actual work done by hospital systems data coding into ICD drive diagnosis Coded diagnoses then go into a single DRG (Diagnosis related group) - of which there are ~800 Average complexity DRGs - $5000 (national efficient price) - increases each year Simple admissions - fractional payment (E.g. $2000), with weighting factor 0.4 Complex high activity admission (E.g. CABG) - $26000, weighting factor 5.3 ABF funding is capped at no more than 6.5% more than the previous year As a result, LHDs have a cap on their spending ABF penalties (where no funding is provided) in the situations of: sentinel events - https://www.safetyandquality.gov.au/our-work/indicators/australian-sentinel-events-list/ hospital acquired complications - https://www.safetyandquality.gov.au/our-work/indicators/hospital-acquired-complications/ Avoidable readmissions - https://www.safetyandquality.gov.au/our-work/indicators/avoidable-hospital-readmissions/ ABF formula \\[\\text{Price weight (NWAU)} \\times \\text{Volume} \\times \\text{Price} \\] NWAU Cost of hospital services - 'currency' used to express price weights for all services Volume/activity Clinically meaningful activity Resource use homogenous activities State funding model References https://insightplus.mja.com.au/2018/47/explainer-hospital-funding-in-a-nutshell/ https://aci.health.nsw.gov.au/__data/assets/pdf_file/0009/230769/NSW-Funding-ABF.pdf https://www.health.vic.gov.au/funding-performance-accountability/cost-weight-calculators-and-episodes-of-care https://www.ihpa.gov.au/what-we-do/national-weighted-activity-unit-nwau-calculators","title":"Hospital funding"},{"location":"Healthcare%20Economics/Hospital%20Funding/#hospital-funding","text":"","title":"Hospital funding"},{"location":"Healthcare%20Economics/Hospital%20Funding/#hospital-levels","text":"Local health networks (Local health districts) Groups/networks of neighbouring hospitals Cost for a hospital bed per day $1500 for a non-acute bed $2000 for an acute bed","title":"Hospital levels"},{"location":"Healthcare%20Economics/Hospital%20Funding/#money-in-hospitals","text":"state or territory health department sign agreements with LHDs - they are the 'purchaser' LHD is the 'service provider' https://www.sahealth.sa.gov.au/wps/wcm/connect/public+content/sa+health+internet/about+us/our+local+health+networks/service+level+agreements https://www.health.qld.gov.au/system-governance/health-system/managing/agreements-deeds Commonwealth reimbusement to the state ~45% of overall cost is reimbursed to the state Payment is based on Activity-Based Funding (ABF) reflection of actual work done by hospital systems data coding into ICD drive diagnosis Coded diagnoses then go into a single DRG (Diagnosis related group) - of which there are ~800 Average complexity DRGs - $5000 (national efficient price) - increases each year Simple admissions - fractional payment (E.g. $2000), with weighting factor 0.4 Complex high activity admission (E.g. CABG) - $26000, weighting factor 5.3 ABF funding is capped at no more than 6.5% more than the previous year As a result, LHDs have a cap on their spending ABF penalties (where no funding is provided) in the situations of: sentinel events - https://www.safetyandquality.gov.au/our-work/indicators/australian-sentinel-events-list/ hospital acquired complications - https://www.safetyandquality.gov.au/our-work/indicators/hospital-acquired-complications/ Avoidable readmissions - https://www.safetyandquality.gov.au/our-work/indicators/avoidable-hospital-readmissions/","title":"Money in hospitals"},{"location":"Healthcare%20Economics/Hospital%20Funding/#abf-formula","text":"\\[\\text{Price weight (NWAU)} \\times \\text{Volume} \\times \\text{Price} \\] NWAU Cost of hospital services - 'currency' used to express price weights for all services Volume/activity Clinically meaningful activity Resource use homogenous activities","title":"ABF formula"},{"location":"Healthcare%20Economics/Hospital%20Funding/#state-funding-model","text":"","title":"State funding model"},{"location":"Healthcare%20Economics/Hospital%20Funding/#references","text":"https://insightplus.mja.com.au/2018/47/explainer-hospital-funding-in-a-nutshell/ https://aci.health.nsw.gov.au/__data/assets/pdf_file/0009/230769/NSW-Funding-ABF.pdf https://www.health.vic.gov.au/funding-performance-accountability/cost-weight-calculators-and-episodes-of-care https://www.ihpa.gov.au/what-we-do/national-weighted-activity-unit-nwau-calculators","title":"References"},{"location":"Healthcare%20Economics/Statistical%20methods%20in%20healthcare%20economics/","text":"Statistical methods in healthcare economics 12 categories of statistical methods Methods based on normal dsitribution Methods following transformation of data Single distribution generalised linear models Parametric models based on skewed distributions outside GLM family Models based on mixtures of parametric distributions two (or multi)-part and Tobit models survival methods non-parametric methods methods based on truncation or trimming of data data components models methods based on averaging across models Markov chain methods Recommendations 1. simple methods are preferred in large samples where near-normality of sample means is assured 2. in smaller samples, relatively simple methods, able to deal with 1 or 2 of above data characteristics are preferable (but you need to check sensitivity to assumptions) 3. more complex methods hold promise but are relatively untried - not currently recommended for wider applied work. Resources https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3470917/pdf/hec0020-0897.pdf https://journals.lww.com/spinejournal/Fulltext/2019/08150/Identifying_Predictors_of_Higher_Acute_Care_Costs.14.aspx","title":"Statistical methods in healthcare economics"},{"location":"Healthcare%20Economics/Statistical%20methods%20in%20healthcare%20economics/#statistical-methods-in-healthcare-economics","text":"","title":"Statistical methods in healthcare economics"},{"location":"Healthcare%20Economics/Statistical%20methods%20in%20healthcare%20economics/#12-categories-of-statistical-methods","text":"Methods based on normal dsitribution Methods following transformation of data Single distribution generalised linear models Parametric models based on skewed distributions outside GLM family Models based on mixtures of parametric distributions two (or multi)-part and Tobit models survival methods non-parametric methods methods based on truncation or trimming of data data components models methods based on averaging across models Markov chain methods Recommendations 1. simple methods are preferred in large samples where near-normality of sample means is assured 2. in smaller samples, relatively simple methods, able to deal with 1 or 2 of above data characteristics are preferable (but you need to check sensitivity to assumptions) 3. more complex methods hold promise but are relatively untried - not currently recommended for wider applied work.","title":"12 categories of statistical methods"},{"location":"Healthcare%20Economics/Statistical%20methods%20in%20healthcare%20economics/#resources","text":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3470917/pdf/hec0020-0897.pdf https://journals.lww.com/spinejournal/Fulltext/2019/08150/Identifying_Predictors_of_Higher_Acute_Care_Costs.14.aspx","title":"Resources"}]}